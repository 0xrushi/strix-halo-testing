{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:43:48Z", "avg_ns": 73247447, "stddev_ns": 394886, "avg_ts": 13.652669, "stddev_ts": 0.073229, "samples_ns": [ 73098366, 73913729, 73189478, 72861663, 73173999 ],"samples_ts": [ 13.6802, 13.5293, 13.6632, 13.7246, 13.6661 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:43:51Z", "avg_ns": 87528538, "stddev_ns": 524508, "avg_ts": 22.850346, "stddev_ts": 0.136909, "samples_ns": [ 87761951, 88214692, 87620435, 87188113, 86857502 ],"samples_ts": [ 22.7889, 22.672, 22.8257, 22.9389, 23.0262 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:43:54Z", "avg_ns": 105902727, "stddev_ns": 1278802, "avg_ts": 37.774869, "stddev_ts": 0.451270, "samples_ns": [ 106129195, 108016061, 105237158, 104766313, 105364909 ],"samples_ts": [ 37.6899, 37.0315, 38.0094, 38.1802, 37.9633 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:43:56Z", "avg_ns": 170540705, "stddev_ns": 1221661, "avg_ts": 46.911532, "stddev_ts": 0.333271, "samples_ns": [ 169860211, 172663688, 170003960, 169699619, 170476047 ],"samples_ts": [ 47.0976, 46.3328, 47.0577, 47.1421, 46.9274 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:43:59Z", "avg_ns": 148620968, "stddev_ns": 1401711, "avg_ts": 107.664077, "stddev_ts": 1.016069, "samples_ns": [ 149585072, 146803696, 148602596, 150330803, 147782675 ],"samples_ts": [ 106.963, 108.989, 107.67, 106.432, 108.267 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:44:02Z", "avg_ns": 208812760, "stddev_ns": 2147079, "avg_ts": 153.260307, "stddev_ts": 1.576490, "samples_ns": [ 209689664, 209692930, 206623743, 211479307, 206578157 ],"samples_ts": [ 152.606, 152.604, 154.871, 151.315, 154.905 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:44:10Z", "avg_ns": 3865644514, "stddev_ns": 18763276, "avg_ts": 33.112825, "stddev_ts": 0.160549, "samples_ns": [ 3863127611, 3871105384, 3892997022, 3859578908, 3841413645 ],"samples_ts": [ 33.1338, 33.0655, 32.8796, 33.1642, 33.3211 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:44:35Z", "avg_ns": 5269351974, "stddev_ns": 10089191, "avg_ts": 48.582966, "stddev_ts": 0.092958, "samples_ns": [ 5284034728, 5271813002, 5259339403, 5260316540, 5271256198 ],"samples_ts": [ 48.4478, 48.5601, 48.6753, 48.6663, 48.5653 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:45:09Z", "avg_ns": 8442825964, "stddev_ns": 38385225, "avg_ts": 60.644205, "stddev_ts": 0.275786, "samples_ns": [ 8392478586, 8486980047, 8429618894, 8475402227, 8429650067 ],"samples_ts": [ 61.007, 60.3277, 60.7382, 60.4101, 60.738 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:46:02Z", "avg_ns": 17184357728, "stddev_ns": 66140323, "avg_ts": 59.589782, "stddev_ts": 0.229219, "samples_ns": [ 17272614519, 17103462367, 17225651395, 17148283090, 17171777270 ],"samples_ts": [ 59.2846, 59.8709, 59.4462, 59.7144, 59.6327 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:47:47Z", "avg_ns": 41495153871, "stddev_ns": 54612064, "avg_ts": 49.355229, "stddev_ts": 0.064992, "samples_ns": [ 41523074823, 41534297998, 41452233871, 41544255057, 41421907606 ],"samples_ts": [ 49.322, 49.3086, 49.4063, 49.2968, 49.4424 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:51:58Z", "avg_ns": 71611401575, "stddev_ns": 3719918661, "avg_ts": 57.197620, "stddev_ts": 0.041782, "samples_ns": [ 71673351102, 71609736551, 71653997051, 71559964968, 71559958204 ],"samples_ts": [ 57.1482, 57.1989, 57.1636, 57.2387, 57.2387 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T13:59:10Z", "avg_ns": 161192309840, "stddev_ns": 318679095, "avg_ts": 50.821442, "stddev_ts": 0.100632, "samples_ns": [ 160673769983, 161410852144, 161196300153, 161189061835, 161491565088 ],"samples_ts": [ 50.9853, 50.7525, 50.82, 50.8223, 50.7271 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-14T14:15:19Z", "avg_ns": 73441084, "stddev_ns": 240339, "avg_ts": 13.616473, "stddev_ts": 0.044496, "samples_ns": [ 73523527, 73167588, 73307781, 73404413, 73802111 ],"samples_ts": [ 13.6011, 13.6673, 13.6411, 13.6232, 13.5497 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-14T14:15:21Z", "avg_ns": 146636835, "stddev_ns": 211371, "avg_ts": 13.639160, "stddev_ts": 0.019603, "samples_ns": [ 146940252, 146387813, 146520273, 146732101, 146603739 ],"samples_ts": [ 13.611, 13.6623, 13.65, 13.6303, 13.6422 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-14T14:15:24Z", "avg_ns": 293122003, "stddev_ns": 303856, "avg_ts": 13.646207, "stddev_ts": 0.014159, "samples_ns": [ 293333305, 292623419, 293058147, 293225622, 293369522 ],"samples_ts": [ 13.6364, 13.6694, 13.6492, 13.6414, 13.6347 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-14T14:15:28Z", "avg_ns": 586402666, "stddev_ns": 530807, "avg_ts": 13.642512, "stddev_ts": 0.012341, "samples_ns": [ 586885017, 585664731, 586649392, 586785618, 586028574 ],"samples_ts": [ 13.6313, 13.6597, 13.6368, 13.6336, 13.6512 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-14T14:15:33Z", "avg_ns": 1174198368, "stddev_ns": 387294, "avg_ts": 13.626319, "stddev_ts": 0.004478, "samples_ns": [ 1174483975, 1174522416, 1173907708, 1174408568, 1173669175 ],"samples_ts": [ 13.623, 13.6226, 13.6297, 13.6239, 13.6325 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-14T14:15:41Z", "avg_ns": 2348517155, "stddev_ns": 802628, "avg_ts": 13.625620, "stddev_ts": 0.004640, "samples_ns": [ 2347946098, 2349437215, 2348561169, 2347512478, 2349128819 ],"samples_ts": [ 13.6289, 13.6203, 13.6254, 13.6315, 13.6221 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-14T14:15:55Z", "avg_ns": 4695981509, "stddev_ns": 2093494, "avg_ts": 13.628676, "stddev_ts": 0.006071, "samples_ns": [ 4698033606, 4697331603, 4696281836, 4695632743, 4692627761 ],"samples_ts": [ 13.6227, 13.6248, 13.6278, 13.6297, 13.6384 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-14T14:16:20Z", "avg_ns": 9435813550, "stddev_ns": 2175812, "avg_ts": 13.565339, "stddev_ts": 0.003123, "samples_ns": [ 9438286957, 9434046697, 9435583424, 9433398864, 9437751811 ],"samples_ts": [ 13.5618, 13.5679, 13.5657, 13.5688, 13.5626 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-14T14:17:09Z", "avg_ns": 18947938220, "stddev_ns": 3314271, "avg_ts": 13.510705, "stddev_ts": 0.002359, "samples_ns": [ 18953165825, 18944761029, 18945490304, 18947754672, 18948519274 ],"samples_ts": [ 13.507, 13.513, 13.5125, 13.5108, 13.5103 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-14T14:18:46Z", "avg_ns": 38444071216, "stddev_ns": 11157082, "avg_ts": 13.318049, "stddev_ts": 0.003864, "samples_ns": [ 38460630570, 38445158065, 38431871818, 38435929530, 38446766099 ],"samples_ts": [ 13.3123, 13.3177, 13.3223, 13.3209, 13.3171 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-14T14:22:00Z", "avg_ns": 78625475337, "stddev_ns": 7765574, "avg_ts": 13.023769, "stddev_ts": 0.001285, "samples_ns": [ 78612681874, 78623673470, 78630143439, 78629298340, 78631579566 ],"samples_ts": [ 13.0259, 13.0241, 13.023, 13.0231, 13.0228 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-14T14:28:35Z", "avg_ns": 164914546132, "stddev_ns": 3170693, "avg_ts": 12.418553, "stddev_ts": 0.000236, "samples_ns": [ 164913073515, 164911086773, 164919519160, 164914947562, 164914103653 ],"samples_ts": [ 12.4187, 12.4188, 12.4182, 12.4185, 12.4186 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-14T14:42:22Z", "avg_ns": 356615020340, "stddev_ns": 6703148, "avg_ts": 11.485775, "stddev_ts": 0.000215, "samples_ns": [ 356623977141, 356611782404, 356609048613, 356620275786, 356610017757 ],"samples_ts": [ 11.4855, 11.4859, 11.486, 11.4856, 11.4859 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-14T15:12:07Z", "avg_ns": 816388873944, "stddev_ns": 23369732, "avg_ts": 10.034434, "stddev_ts": 0.000287, "samples_ns": [ 816352767320, 816385439970, 816387473618, 816405532801, 816413156011 ],"samples_ts": [ 10.0349, 10.0345, 10.0345, 10.0342, 10.0341 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:11Z", "avg_ns": 75911230, "stddev_ns": 74403, "avg_ts": 13.173291, "stddev_ts": 0.012868, "samples_ns": [ 75806179, 76014390, 75916446, 75897711, 75921425 ],"samples_ts": [ 13.1915, 13.1554, 13.1724, 13.1756, 13.1715 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:14Z", "avg_ns": 90361423, "stddev_ns": 304317, "avg_ts": 22.133539, "stddev_ts": 0.074469, "samples_ns": [ 90735292, 90623742, 90030908, 90262012, 90155162 ],"samples_ts": [ 22.0421, 22.0693, 22.2146, 22.1577, 22.184 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:16Z", "avg_ns": 108965296, "stddev_ns": 733895, "avg_ts": 36.710268, "stddev_ts": 0.247319, "samples_ns": [ 108890119, 109991569, 108952105, 107923843, 109068844 ],"samples_ts": [ 36.7343, 36.3664, 36.7134, 37.0632, 36.6741 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:19Z", "avg_ns": 177040216, "stddev_ns": 2856432, "avg_ts": 45.196790, "stddev_ts": 0.721853, "samples_ns": [ 178064672, 181490492, 175726837, 175795787, 174123293 ],"samples_ts": [ 44.9275, 44.0794, 45.5252, 45.5073, 45.9445 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:22Z", "avg_ns": 158952712, "stddev_ns": 298727, "avg_ts": 100.659153, "stddev_ts": 0.189532, "samples_ns": [ 158449539, 158915326, 159187327, 159121915, 159089453 ],"samples_ts": [ 100.979, 100.683, 100.511, 100.552, 100.572 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:25Z", "avg_ns": 227741695, "stddev_ns": 1320940, "avg_ts": 140.513830, "stddev_ts": 0.811720, "samples_ns": [ 226896915, 228258445, 227214662, 226532911, 229805543 ],"samples_ts": [ 141.033, 140.192, 140.836, 141.26, 139.248 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:28Z", "avg_ns": 2313181994, "stddev_ns": 7565184, "avg_ts": 27.667753, "stddev_ts": 0.090433, "samples_ns": [ 2305738862, 2323504346, 2315970194, 2305704767, 2314991805 ],"samples_ts": [ 27.7568, 27.5446, 27.6342, 27.7572, 27.6459 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:20:44Z", "avg_ns": 3942972368, "stddev_ns": 22755917, "avg_ts": 32.463685, "stddev_ts": 0.187466, "samples_ns": [ 3921658116, 3950626901, 3955375207, 3970094295, 3917107322 ],"samples_ts": [ 32.6393, 32.3999, 32.361, 32.241, 32.6772 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:21:10Z", "avg_ns": 5245994324, "stddev_ns": 11914253, "avg_ts": 48.799339, "stddev_ts": 0.110895, "samples_ns": [ 5240634516, 5229311881, 5256701798, 5245264188, 5258059239 ],"samples_ts": [ 48.849, 48.9548, 48.6997, 48.8059, 48.6872 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:21:43Z", "avg_ns": 9624967168, "stddev_ns": 44723992, "avg_ts": 53.195905, "stddev_ts": 0.246986, "samples_ns": [ 9644882241, 9687989552, 9612792308, 9567443242, 9611728498 ],"samples_ts": [ 53.0851, 52.8489, 53.2624, 53.5148, 53.2683 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:22:43Z", "avg_ns": 16996973961, "stddev_ns": 34004257, "avg_ts": 60.246211, "stddev_ts": 0.120601, "samples_ns": [ 17014444438, 17002028087, 16947817253, 16982692518, 17037887513 ],"samples_ts": [ 60.1842, 60.2281, 60.4208, 60.2967, 60.1013 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:24:26Z", "avg_ns": 40959082503, "stddev_ns": 53314580, "avg_ts": 50.001188, "stddev_ts": 0.065054, "samples_ns": [ 40953373427, 40919800425, 41035393282, 40985135884, 40901709501 ],"samples_ts": [ 50.0081, 50.0491, 49.9081, 49.9693, 50.0713 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:28:34Z", "avg_ns": 84977157426, "stddev_ns": 297934854, "avg_ts": 48.201662, "stddev_ts": 0.168901, "samples_ns": [ 84633004335, 84801417290, 84880877288, 85227668411, 85342819807 ],"samples_ts": [ 48.3972, 48.3011, 48.2559, 48.0595, 47.9947 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T16:37:06Z", "avg_ns": 203276976215, "stddev_ns": 362262100, "avg_ts": 40.299797, "stddev_ts": 0.071963, "samples_ns": [ 202650488973, 203304899724, 203564593433, 203449795936, 203415103009 ],"samples_ts": [ 40.4243, 40.2942, 40.2428, 40.2655, 40.2723 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-14T16:57:27Z", "avg_ns": 75990135, "stddev_ns": 132487, "avg_ts": 13.159635, "stddev_ts": 0.022865, "samples_ns": [ 76141067, 76058091, 75980266, 75784968, 75986287 ],"samples_ts": [ 13.1335, 13.1478, 13.1613, 13.1952, 13.1603 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-14T16:57:30Z", "avg_ns": 151798924, "stddev_ns": 308279, "avg_ts": 13.175367, "stddev_ts": 0.026728, "samples_ns": [ 152153022, 151389638, 151911668, 151959439, 151580857 ],"samples_ts": [ 13.1447, 13.2109, 13.1655, 13.1614, 13.1943 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-14T16:57:32Z", "avg_ns": 303573341, "stddev_ns": 409701, "avg_ts": 13.176407, "stddev_ts": 0.017772, "samples_ns": [ 303520978, 304066675, 303245391, 303911012, 303122650 ],"samples_ts": [ 13.1787, 13.155, 13.1906, 13.1617, 13.196 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-14T16:57:36Z", "avg_ns": 607812270, "stddev_ns": 784436, "avg_ts": 13.161976, "stddev_ts": 0.016963, "samples_ns": [ 607577945, 607158307, 607436068, 609164859, 607724171 ],"samples_ts": [ 13.167, 13.1761, 13.1701, 13.1327, 13.1639 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-14T16:57:41Z", "avg_ns": 1214883295, "stddev_ns": 1016604, "avg_ts": 13.169997, "stddev_ts": 0.011006, "samples_ns": [ 1216354144, 1214544212, 1214782621, 1213560243, 1215175259 ],"samples_ts": [ 13.1541, 13.1737, 13.1711, 13.1843, 13.1668 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-14T16:57:49Z", "avg_ns": 2430854219, "stddev_ns": 1037022, "avg_ts": 13.164099, "stddev_ts": 0.005608, "samples_ns": [ 2430981506, 2432513585, 2429865709, 2430118566, 2430791731 ],"samples_ts": [ 13.1634, 13.1551, 13.1695, 13.1681, 13.1644 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-14T16:58:03Z", "avg_ns": 4860250366, "stddev_ns": 1527014, "avg_ts": 13.168047, "stddev_ts": 0.004131, "samples_ns": [ 4859337956, 4860366652, 4861708407, 4861666832, 4858171986 ],"samples_ts": [ 13.1705, 13.1677, 13.1641, 13.1642, 13.1737 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-14T16:58:30Z", "avg_ns": 9721176397, "stddev_ns": 1412504, "avg_ts": 13.167131, "stddev_ts": 0.001911, "samples_ns": [ 9722307782, 9719113048, 9722664264, 9721065069, 9720731823 ],"samples_ts": [ 13.1656, 13.1699, 13.1651, 13.1673, 13.1677 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-14T16:59:20Z", "avg_ns": 19437820717, "stddev_ns": 2605063, "avg_ts": 13.170201, "stddev_ts": 0.001762, "samples_ns": [ 19441860597, 19437154411, 19435487407, 19438769882, 19435831290 ],"samples_ts": [ 13.1675, 13.1707, 13.1718, 13.1696, 13.1715 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-14T17:01:00Z", "avg_ns": 38882673211, "stddev_ns": 5350197, "avg_ts": 13.167819, "stddev_ts": 0.001809, "samples_ns": [ 38884473514, 38882597174, 38874647908, 38882171096, 38889476367 ],"samples_ts": [ 13.1672, 13.1678, 13.1705, 13.168, 13.1655 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-14T17:04:16Z", "avg_ns": 78212717281, "stddev_ns": 6720053, "avg_ts": 13.092500, "stddev_ts": 0.001124, "samples_ns": [ 78223408807, 78210232057, 78214384447, 78209819724, 78205741372 ],"samples_ts": [ 13.0907, 13.0929, 13.0922, 13.093, 13.0937 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-14T17:10:49Z", "avg_ns": 161118267914, "stddev_ns": 6237159, "avg_ts": 12.711160, "stddev_ts": 0.000492, "samples_ns": [ 161109276624, 161118152882, 161115729335, 161124593294, 161123587435 ],"samples_ts": [ 12.7119, 12.7112, 12.7114, 12.7107, 12.7107 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-14T17:24:17Z", "avg_ns": 341542011043, "stddev_ns": 12584397, "avg_ts": 11.992668, "stddev_ts": 0.000441, "samples_ns": [ 341539120321, 341550375337, 341544725896, 341521902950, 341553930713 ],"samples_ts": [ 11.9928, 11.9924, 11.9926, 11.9934, 11.9922 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-14T17:52:47Z", "avg_ns": 763992110331, "stddev_ns": 40619126, "avg_ts": 10.722624, "stddev_ts": 0.000570, "samples_ns": [ 764011145083, 764017583400, 764015323187, 763995375273, 763921124712 ],"samples_ts": [ 10.7224, 10.7223, 10.7223, 10.7226, 10.7236 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:29Z", "avg_ns": 73263022, "stddev_ns": 126962, "avg_ts": 13.649483, "stddev_ts": 0.023608, "samples_ns": [ 73225117, 73416547, 73085675, 73239936, 73347837 ],"samples_ts": [ 13.6565, 13.6209, 13.6826, 13.6538, 13.6337 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:31Z", "avg_ns": 87218564, "stddev_ns": 216256, "avg_ts": 22.931011, "stddev_ts": 0.056915, "samples_ns": [ 87257499, 87472694, 87218226, 87269622, 86874780 ],"samples_ts": [ 22.9207, 22.8643, 22.931, 22.9175, 23.0216 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:34Z", "avg_ns": 105687299, "stddev_ns": 894873, "avg_ts": 37.849671, "stddev_ts": 0.320621, "samples_ns": [ 106461351, 106647380, 105780320, 104731600, 104815848 ],"samples_ts": [ 37.5723, 37.5068, 37.8142, 38.1929, 38.1622 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:36Z", "avg_ns": 213059562, "stddev_ns": 1351700, "avg_ts": 37.549393, "stddev_ts": 0.237946, "samples_ns": [ 211875844, 214734407, 211679465, 212871365, 214136733 ],"samples_ts": [ 37.758, 37.2553, 37.793, 37.5814, 37.3593 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:40Z", "avg_ns": 190872908, "stddev_ns": 1804386, "avg_ts": 83.831420, "stddev_ts": 0.794550, "samples_ns": [ 190878643, 192593055, 192585792, 188373334, 189933717 ],"samples_ts": [ 83.8229, 83.0767, 83.0799, 84.9377, 84.2399 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:43Z", "avg_ns": 251414360, "stddev_ns": 1306564, "avg_ts": 127.282661, "stddev_ts": 0.659222, "samples_ns": [ 251377082, 253458905, 250296061, 250263070, 251676686 ],"samples_ts": [ 127.299, 126.253, 127.849, 127.865, 127.147 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:46Z", "avg_ns": 725484596, "stddev_ns": 930791, "avg_ts": 88.217013, "stddev_ts": 0.113158, "samples_ns": [ 725964363, 725373914, 724105671, 725354148, 726624887 ],"samples_ts": [ 88.1586, 88.2304, 88.3849, 88.2328, 88.0785 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:56:53Z", "avg_ns": 814279609, "stddev_ns": 1510338, "avg_ts": 157.194594, "stddev_ts": 0.291696, "samples_ns": [ 815279624, 814629693, 812164590, 815933444, 813390696 ],"samples_ts": [ 157.001, 157.127, 157.604, 156.876, 157.366 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:57:00Z", "avg_ns": 1203303185, "stddev_ns": 1125198, "avg_ts": 212.747861, "stddev_ts": 0.198889, "samples_ns": [ 1201719008, 1204579675, 1204148606, 1203209132, 1202859506 ],"samples_ts": [ 213.028, 212.522, 212.598, 212.764, 212.826 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:57:09Z", "avg_ns": 1615668122, "stddev_ns": 4709144, "avg_ts": 316.898916, "stddev_ts": 0.922762, "samples_ns": [ 1614208577, 1618811859, 1622109488, 1612649571, 1610561117 ],"samples_ts": [ 317.183, 316.281, 315.638, 317.49, 317.902 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:57:20Z", "avg_ns": 3375343085, "stddev_ns": 13920251, "avg_ts": 303.380685, "stddev_ts": 1.247941, "samples_ns": [ 3397604671, 3359296511, 3375527612, 3373010778, 3371275854 ],"samples_ts": [ 301.389, 304.826, 303.36, 303.586, 303.743 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:57:43Z", "avg_ns": 7178767917, "stddev_ns": 11316008, "avg_ts": 285.286292, "stddev_ts": 0.450413, "samples_ns": [ 7185883611, 7159621410, 7183591928, 7177590987, 7187151652 ],"samples_ts": [ 285.003, 286.049, 285.094, 285.333, 284.953 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T18:58:28Z", "avg_ns": 16079696123, "stddev_ns": 16859861, "avg_ts": 254.731406, "stddev_ts": 0.266901, "samples_ns": [ 16088818193, 16070176360, 16105106008, 16065670466, 16068709591 ],"samples_ts": [ 254.587, 254.882, 254.329, 254.954, 254.905 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T19:00:07Z", "avg_ns": 39017214026, "stddev_ns": 22292499, "avg_ts": 209.958664, "stddev_ts": 0.119970, "samples_ns": [ 39035145814, 39024490466, 39039332085, 38994978003, 38992123764 ],"samples_ts": [ 209.862, 209.919, 209.84, 210.078, 210.094 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-14T19:04:03Z", "avg_ns": 73482797, "stddev_ns": 157916, "avg_ts": 13.608678, "stddev_ts": 0.029245, "samples_ns": [ 73569949, 73579858, 73342672, 73284713, 73636794 ],"samples_ts": [ 13.5925, 13.5907, 13.6346, 13.6454, 13.5802 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-14T19:04:05Z", "avg_ns": 146672794, "stddev_ns": 359505, "avg_ts": 13.635859, "stddev_ts": 0.033345, "samples_ns": [ 147195934, 146438160, 146874169, 146543037, 146312674 ],"samples_ts": [ 13.5873, 13.6576, 13.6171, 13.6479, 13.6694 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-14T19:04:08Z", "avg_ns": 293412016, "stddev_ns": 77104, "avg_ts": 13.632708, "stddev_ts": 0.003493, "samples_ns": [ 293507707, 293370498, 293454546, 293312469, 293414862 ],"samples_ts": [ 13.6283, 13.6346, 13.6307, 13.6373, 13.6326 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-14T19:04:12Z", "avg_ns": 586291968, "stddev_ns": 375093, "avg_ts": 13.645083, "stddev_ts": 0.008728, "samples_ns": [ 586005866, 586828011, 586453398, 585882675, 586289890 ],"samples_ts": [ 13.6517, 13.6326, 13.6413, 13.6546, 13.6451 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-14T19:04:16Z", "avg_ns": 1172969745, "stddev_ns": 485799, "avg_ts": 13.640592, "stddev_ts": 0.005648, "samples_ns": [ 1172624295, 1172687424, 1173714324, 1172608236, 1173214446 ],"samples_ts": [ 13.6446, 13.6439, 13.6319, 13.6448, 13.6377 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-14T19:04:24Z", "avg_ns": 2344322028, "stddev_ns": 887490, "avg_ts": 13.650003, "stddev_ts": 0.005168, "samples_ns": [ 2344193291, 2345271900, 2343053161, 2345056518, 2344035270 ],"samples_ts": [ 13.6508, 13.6445, 13.6574, 13.6457, 13.6517 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-14T19:04:38Z", "avg_ns": 4692827281, "stddev_ns": 1356958, "avg_ts": 13.637835, "stddev_ts": 0.003938, "samples_ns": [ 4694631668, 4693775805, 4692420222, 4691284313, 4692024399 ],"samples_ts": [ 13.6326, 13.6351, 13.639, 13.6423, 13.6402 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-14T19:05:04Z", "avg_ns": 9428783638, "stddev_ns": 2320010, "avg_ts": 13.575453, "stddev_ts": 0.003340, "samples_ns": [ 9432261908, 9427276908, 9427037128, 9427241862, 9430100384 ],"samples_ts": [ 13.5704, 13.5776, 13.578, 13.5777, 13.5736 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-14T19:05:53Z", "avg_ns": 18927282420, "stddev_ns": 2944735, "avg_ts": 13.525450, "stddev_ts": 0.002100, "samples_ns": [ 18930797323, 18929603145, 18925094011, 18923822669, 18927094956 ],"samples_ts": [ 13.5229, 13.5238, 13.527, 13.5279, 13.5256 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-14T19:07:29Z", "avg_ns": 38419398060, "stddev_ns": 4167393, "avg_ts": 13.326601, "stddev_ts": 0.001445, "samples_ns": [ 38421939232, 38417849187, 38413594182, 38419040280, 38424567420 ],"samples_ts": [ 13.3257, 13.3271, 13.3286, 13.3267, 13.3248 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-14T19:10:44Z", "avg_ns": 78602204806, "stddev_ns": 7279375, "avg_ts": 13.027624, "stddev_ts": 0.001206, "samples_ns": [ 78609958281, 78599341946, 78604996208, 78605645003, 78591082594 ],"samples_ts": [ 13.0263, 13.0281, 13.0272, 13.0271, 13.0295 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-14T19:17:19Z", "avg_ns": 164914166660, "stddev_ns": 9068959, "avg_ts": 12.418581, "stddev_ts": 0.000682, "samples_ns": [ 164924624298, 164921914642, 164904831733, 164905724085, 164913738545 ],"samples_ts": [ 12.4178, 12.418, 12.4193, 12.4192, 12.4186 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-14T19:31:05Z", "avg_ns": 356396934084, "stddev_ns": 20854287, "avg_ts": 11.492804, "stddev_ts": 0.000673, "samples_ns": [ 356416110687, 356397822225, 356403860367, 356361542872, 356405334269 ],"samples_ts": [ 11.4922, 11.4928, 11.4926, 11.4939, 11.4925 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-14T20:00:49Z", "avg_ns": 816306618597, "stddev_ns": 39019844, "avg_ts": 10.035445, "stddev_ts": 0.000480, "samples_ns": [ 816318455286, 816326403116, 816335398276, 816238308952, 816314527356 ],"samples_ts": [ 10.0353, 10.0352, 10.0351, 10.0363, 10.0353 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:08:53Z", "avg_ns": 75933869, "stddev_ns": 334096, "avg_ts": 13.169558, "stddev_ts": 0.057968, "samples_ns": [ 75952601, 76162545, 75755430, 75475615, 76323157 ],"samples_ts": [ 13.1661, 13.1298, 13.2004, 13.2493, 13.1022 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:08:55Z", "avg_ns": 90409928, "stddev_ns": 327360, "avg_ts": 22.121696, "stddev_ts": 0.080096, "samples_ns": [ 90055438, 90801079, 90108197, 90651608, 90433318 ],"samples_ts": [ 22.2085, 22.0262, 22.1955, 22.0625, 22.1157 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:08:58Z", "avg_ns": 108463407, "stddev_ns": 684326, "avg_ts": 36.879972, "stddev_ts": 0.232704, "samples_ns": [ 108822848, 109363854, 108441843, 107556129, 108132361 ],"samples_ts": [ 36.757, 36.5752, 36.8861, 37.1899, 36.9917 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:01Z", "avg_ns": 175220929, "stddev_ns": 2739856, "avg_ts": 45.665409, "stddev_ts": 0.700520, "samples_ns": [ 173400158, 180045013, 174676977, 173746148, 174236349 ],"samples_ts": [ 46.1361, 44.4333, 45.7988, 46.0442, 45.9146 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:04Z", "avg_ns": 158916863, "stddev_ns": 1161238, "avg_ts": 100.685895, "stddev_ts": 0.739227, "samples_ns": [ 160042603, 157116635, 159367975, 158455671, 159601434 ],"samples_ts": [ 99.9734, 101.835, 100.397, 100.975, 100.25 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:07Z", "avg_ns": 225755679, "stddev_ns": 1376988, "avg_ts": 141.750363, "stddev_ts": 0.861954, "samples_ns": [ 227769050, 224494377, 225347250, 226509354, 224658366 ],"samples_ts": [ 140.493, 142.543, 142.003, 141.275, 142.438 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:10Z", "avg_ns": 715957007, "stddev_ns": 769272, "avg_ts": 89.390925, "stddev_ts": 0.095883, "samples_ns": [ 715909930, 716156434, 715508026, 715087036, 717123613 ],"samples_ts": [ 89.3967, 89.3659, 89.4469, 89.4996, 89.2454 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:16Z", "avg_ns": 827112982, "stddev_ns": 2100335, "avg_ts": 154.755955, "stddev_ts": 0.392671, "samples_ns": [ 829201875, 824941572, 826121981, 829521088, 825778397 ],"samples_ts": [ 154.365, 155.163, 154.941, 154.306, 155.005 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:23Z", "avg_ns": 1248140320, "stddev_ns": 2701348, "avg_ts": 205.105911, "stddev_ts": 0.442923, "samples_ns": [ 1245988319, 1248519026, 1252662262, 1247067353, 1246464643 ],"samples_ts": [ 205.459, 205.043, 204.365, 205.282, 205.381 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:33Z", "avg_ns": 1898150161, "stddev_ns": 2162048, "avg_ts": 269.736579, "stddev_ts": 0.307355, "samples_ns": [ 1897221564, 1900247335, 1898860344, 1894848922, 1899572643 ],"samples_ts": [ 269.868, 269.439, 269.635, 270.206, 269.534 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:09:46Z", "avg_ns": 4180160287, "stddev_ns": 3428599, "avg_ts": 244.966815, "stddev_ts": 0.200968, "samples_ns": [ 4182918187, 4182400098, 4182086382, 4178526719, 4174870053 ],"samples_ts": [ 244.805, 244.835, 244.854, 245.062, 245.277 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:10:14Z", "avg_ns": 9992639175, "stddev_ns": 9782519, "avg_ts": 204.951018, "stddev_ts": 0.200543, "samples_ns": [ 9988157552, 9985997703, 9983357790, 10006322876, 9999359956 ],"samples_ts": [ 205.043, 205.087, 205.141, 204.671, 204.813 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:11:16Z", "avg_ns": 26903263733, "stddev_ns": 30990338, "avg_ts": 152.249347, "stddev_ts": 0.175366, "samples_ns": [ 26865113878, 26886795210, 26939491112, 26930255151, 26894663315 ],"samples_ts": [ 152.465, 152.342, 152.044, 152.097, 152.298 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T21:13:59Z", "avg_ns": 83618208696, "stddev_ns": 17410342, "avg_ts": 97.969096, "stddev_ts": 0.020393, "samples_ns": [ 83595805700, 83640700643, 83623293796, 83606544625, 83624698720 ],"samples_ts": [ 97.9953, 97.9427, 97.9631, 97.9828, 97.9615 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-14T21:22:23Z", "avg_ns": 75881556, "stddev_ns": 137641, "avg_ts": 13.178468, "stddev_ts": 0.023957, "samples_ns": [ 75987084, 75914207, 75931600, 75640203, 75934686 ],"samples_ts": [ 13.1601, 13.1728, 13.1697, 13.2205, 13.1692 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-14T21:22:25Z", "avg_ns": 151760525, "stddev_ns": 231846, "avg_ts": 13.178682, "stddev_ts": 0.020126, "samples_ns": [ 152072523, 151740590, 151529413, 151906120, 151553979 ],"samples_ts": [ 13.1516, 13.1804, 13.1988, 13.166, 13.1966 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-14T21:22:28Z", "avg_ns": 303236600, "stddev_ns": 320931, "avg_ts": 13.191032, "stddev_ts": 0.013959, "samples_ns": [ 303614740, 303348540, 302732263, 303217244, 303270214 ],"samples_ts": [ 13.1746, 13.1862, 13.213, 13.1919, 13.1896 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-14T21:22:32Z", "avg_ns": 607504683, "stddev_ns": 302549, "avg_ts": 13.168625, "stddev_ts": 0.006525, "samples_ns": [ 607466708, 607138832, 607859416, 607753027, 607305435 ],"samples_ts": [ 13.1694, 13.1766, 13.1609, 13.1632, 13.1729 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-14T21:22:37Z", "avg_ns": 1214910461, "stddev_ns": 825492, "avg_ts": 13.169700, "stddev_ts": 0.008935, "samples_ns": [ 1215863306, 1215727881, 1214544598, 1214313975, 1214102548 ],"samples_ts": [ 13.1594, 13.1608, 13.1737, 13.1762, 13.1785 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-14T21:22:45Z", "avg_ns": 2430478684, "stddev_ns": 1676602, "avg_ts": 13.166136, "stddev_ts": 0.009084, "samples_ns": [ 2431594860, 2428376764, 2431100895, 2432261519, 2429059382 ],"samples_ts": [ 13.1601, 13.1775, 13.1628, 13.1565, 13.1738 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-14T21:22:59Z", "avg_ns": 4862147787, "stddev_ns": 606838, "avg_ts": 13.162907, "stddev_ts": 0.001632, "samples_ns": [ 4862449162, 4861920826, 4861443826, 4863018213, 4861906910 ],"samples_ts": [ 13.1621, 13.1635, 13.1648, 13.1606, 13.1636 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-14T21:23:25Z", "avg_ns": 9712780405, "stddev_ns": 1884989, "avg_ts": 13.178513, "stddev_ts": 0.002552, "samples_ns": [ 9713829220, 9712960736, 9715254924, 9711070242, 9710786906 ],"samples_ts": [ 13.1771, 13.1783, 13.1752, 13.1808, 13.1812 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-14T21:24:16Z", "avg_ns": 19432402282, "stddev_ns": 2227258, "avg_ts": 13.173873, "stddev_ts": 0.001505, "samples_ns": [ 19433247106, 19431262601, 19431637817, 19430053748, 19435810141 ],"samples_ts": [ 13.1733, 13.1746, 13.1744, 13.1755, 13.1716 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-14T21:25:55Z", "avg_ns": 38835912164, "stddev_ns": 3465751, "avg_ts": 13.183674, "stddev_ts": 0.001177, "samples_ns": [ 38838122880, 38834157278, 38838186990, 38830598686, 38838494986 ],"samples_ts": [ 13.1829, 13.1843, 13.1829, 13.1855, 13.1828 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-14T21:29:11Z", "avg_ns": 78123544608, "stddev_ns": 4912137, "avg_ts": 13.107444, "stddev_ts": 0.000823, "samples_ns": [ 78126171595, 78130530492, 78119486487, 78118674327, 78122860140 ],"samples_ts": [ 13.107, 13.1063, 13.1081, 13.1083, 13.1076 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-14T21:35:44Z", "avg_ns": 161030137890, "stddev_ns": 8286986, "avg_ts": 12.718116, "stddev_ts": 0.000654, "samples_ns": [ 161034601584, 161015882332, 161035209436, 161029817773, 161035178326 ],"samples_ts": [ 12.7178, 12.7192, 12.7177, 12.7181, 12.7177 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-14T21:49:11Z", "avg_ns": 341462682517, "stddev_ns": 16532306, "avg_ts": 11.995454, "stddev_ts": 0.000580, "samples_ns": [ 341487226750, 341445630237, 341449506850, 341463408638, 341467640112 ],"samples_ts": [ 11.9946, 11.9961, 11.9959, 11.9954, 11.9953 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-14T22:17:41Z", "avg_ns": 763145488107, "stddev_ns": 44635432, "avg_ts": 10.734519, "stddev_ts": 0.000628, "samples_ns": [ 763202375981, 763159834159, 763079871665, 763132683184, 763152675550 ],"samples_ts": [ 10.7337, 10.7343, 10.7354, 10.7347, 10.7344 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:19Z", "avg_ns": 69076570, "stddev_ns": 84712, "avg_ts": 14.476706, "stddev_ts": 0.017592, "samples_ns": [ 68949679, 69049047, 69171037, 69089634, 69123457 ],"samples_ts": [ 14.5033, 14.4825, 14.4569, 14.474, 14.4669 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:21Z", "avg_ns": 71957434, "stddev_ns": 242480, "avg_ts": 27.794460, "stddev_ts": 0.093163, "samples_ns": [ 71883340, 72382959, 71906022, 71793250, 71821603 ],"samples_ts": [ 27.8229, 27.6308, 27.8141, 27.8578, 27.8468 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:23Z", "avg_ns": 94426811, "stddev_ns": 1114904, "avg_ts": 42.365526, "stddev_ts": 0.495126, "samples_ns": [ 94536223, 96272771, 94012919, 93345633, 93966511 ],"samples_ts": [ 42.3118, 41.5486, 42.5473, 42.8515, 42.5684 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:26Z", "avg_ns": 179691605, "stddev_ns": 8072021, "avg_ts": 44.590933, "stddev_ts": 1.954473, "samples_ns": [ 176206086, 174524891, 183866800, 191787374, 172072878 ],"samples_ts": [ 45.4014, 45.8387, 43.5098, 41.7129, 46.4919 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:29Z", "avg_ns": 316158978, "stddev_ns": 972118, "avg_ts": 50.607834, "stddev_ts": 0.155500, "samples_ns": [ 314867573, 316220497, 317602259, 316015441, 316089120 ],"samples_ts": [ 50.815, 50.5976, 50.3775, 50.6304, 50.6186 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:33Z", "avg_ns": 342091480, "stddev_ns": 1987555, "avg_ts": 93.544753, "stddev_ts": 0.542821, "samples_ns": [ 341070371, 339831720, 343736448, 344583892, 341234970 ],"samples_ts": [ 93.8223, 94.1643, 93.0946, 92.8656, 93.777 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:37Z", "avg_ns": 456746235, "stddev_ns": 1314338, "avg_ts": 140.122499, "stddev_ts": 0.403296, "samples_ns": [ 455133990, 458292521, 456924397, 457659839, 455720429 ],"samples_ts": [ 140.618, 139.649, 140.067, 139.842, 140.437 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:41Z", "avg_ns": 760097903, "stddev_ns": 2343585, "avg_ts": 168.400639, "stddev_ts": 0.518806, "samples_ns": [ 757880664, 762916366, 762219763, 758066748, 759405976 ],"samples_ts": [ 168.892, 167.777, 167.931, 168.851, 168.553 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:48Z", "avg_ns": 1570885567, "stddev_ns": 3489174, "avg_ts": 162.966046, "stddev_ts": 0.361481, "samples_ns": [ 1571662610, 1576329151, 1570672811, 1568310828, 1567452435 ],"samples_ts": [ 162.885, 162.403, 162.987, 163.233, 163.322 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:21:59Z", "avg_ns": 4292007476, "stddev_ns": 11251483, "avg_ts": 119.292153, "stddev_ts": 0.312466, "samples_ns": [ 4308811460, 4292073419, 4293736779, 4287608912, 4277806811 ],"samples_ts": [ 118.826, 119.29, 119.243, 119.414, 119.687 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:22:27Z", "avg_ns": 8870181952, "stddev_ns": 16469326, "avg_ts": 115.443272, "stddev_ts": 0.214791, "samples_ns": [ 8880427252, 8841730797, 8877597654, 8880926942, 8870227119 ],"samples_ts": [ 115.31, 115.814, 115.347, 115.303, 115.442 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:23:22Z", "avg_ns": 17999528444, "stddev_ns": 18117010, "avg_ts": 113.780851, "stddev_ts": 0.114583, "samples_ns": [ 18000895743, 18019474218, 18010408367, 17995191999, 17971671894 ],"samples_ts": [ 113.772, 113.655, 113.712, 113.808, 113.957 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:25:12Z", "avg_ns": 28839128823, "stddev_ns": 21580801, "avg_ts": 142.029319, "stddev_ts": 0.106232, "samples_ns": [ 28871213624, 28821504016, 28821811238, 28851014699, 28830100541 ],"samples_ts": [ 141.871, 142.116, 142.115, 141.971, 142.074 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-14T23:28:07Z", "avg_ns": 74942779682, "stddev_ns": 27072158, "avg_ts": 109.310075, "stddev_ts": 0.039489, "samples_ns": [ 74954841599, 74970515421, 74920417543, 74907942178, 74960181671 ],"samples_ts": [ 109.292, 109.27, 109.343, 109.361, 109.285 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-14T23:35:38Z", "avg_ns": 69346835, "stddev_ns": 211864, "avg_ts": 14.420376, "stddev_ts": 0.043918, "samples_ns": [ 69209718, 69173580, 69494403, 69646349, 69210129 ],"samples_ts": [ 14.4488, 14.4564, 14.3896, 14.3583, 14.4488 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-14T23:35:41Z", "avg_ns": 138236243, "stddev_ns": 344954, "avg_ts": 14.468058, "stddev_ts": 0.036102, "samples_ns": [ 138053838, 138686889, 138330358, 138342150, 137767981 ],"samples_ts": [ 14.4871, 14.421, 14.4581, 14.4569, 14.5172 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-14T23:35:43Z", "avg_ns": 275880785, "stddev_ns": 663648, "avg_ts": 14.499083, "stddev_ts": 0.034827, "samples_ns": [ 276870650, 276178620, 275560147, 275150616, 275643894 ],"samples_ts": [ 14.4472, 14.4834, 14.5159, 14.5375, 14.5115 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-14T23:35:47Z", "avg_ns": 551564947, "stddev_ns": 1032143, "avg_ts": 14.504226, "stddev_ts": 0.027125, "samples_ns": [ 552710351, 550374520, 551228455, 550936286, 552575126 ],"samples_ts": [ 14.4741, 14.5356, 14.513, 14.5207, 14.4777 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-14T23:35:51Z", "avg_ns": 1104777536, "stddev_ns": 926685, "avg_ts": 14.482562, "stddev_ts": 0.012141, "samples_ns": [ 1105840820, 1105063156, 1103371085, 1104462475, 1105150147 ],"samples_ts": [ 14.4686, 14.4788, 14.501, 14.4867, 14.4777 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-14T23:35:59Z", "avg_ns": 2204114815, "stddev_ns": 1841161, "avg_ts": 14.518308, "stddev_ts": 0.012131, "samples_ns": [ 2204856466, 2201622472, 2206137839, 2202823664, 2205133634 ],"samples_ts": [ 14.5134, 14.5347, 14.505, 14.5268, 14.5116 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-14T23:36:12Z", "avg_ns": 4413942740, "stddev_ns": 1967427, "avg_ts": 14.499511, "stddev_ts": 0.006453, "samples_ns": [ 4417276663, 4413953211, 4412720274, 4412340057, 4413423499 ],"samples_ts": [ 14.4886, 14.4995, 14.5035, 14.5048, 14.5012 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-14T23:36:36Z", "avg_ns": 8825125470, "stddev_ns": 4754135, "avg_ts": 14.504046, "stddev_ts": 0.007812, "samples_ns": [ 8828383489, 8831700730, 8822066108, 8823197245, 8820279778 ],"samples_ts": [ 14.4987, 14.4932, 14.5091, 14.5072, 14.512 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-14T23:37:22Z", "avg_ns": 17683816654, "stddev_ns": 5007402, "avg_ts": 14.476514, "stddev_ts": 0.004096, "samples_ns": [ 17691590097, 17681330086, 17683077074, 17684908977, 17678177040 ],"samples_ts": [ 14.4702, 14.4785, 14.4771, 14.4756, 14.4811 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-14T23:38:52Z", "avg_ns": 35518108961, "stddev_ns": 6966793, "avg_ts": 14.415182, "stddev_ts": 0.002826, "samples_ns": [ 35525024000, 35518283249, 35506550044, 35521442702, 35519244814 ],"samples_ts": [ 14.4124, 14.4151, 14.4199, 14.4138, 14.4147 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-14T23:41:52Z", "avg_ns": 72024636659, "stddev_ns": 13421172, "avg_ts": 14.217358, "stddev_ts": 0.002648, "samples_ns": [ 72016595751, 72034497505, 72020921805, 72042055174, 72009113063 ],"samples_ts": [ 14.2189, 14.2154, 14.2181, 14.2139, 14.2204 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-14T23:47:54Z", "avg_ns": 149163721211, "stddev_ns": 20225219, "avg_ts": 13.729880, "stddev_ts": 0.001862, "samples_ns": [ 149131200340, 149185548727, 149162113817, 149166410913, 149173332258 ],"samples_ts": [ 13.7329, 13.7279, 13.73, 13.7296, 13.729 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-15T00:00:21Z", "avg_ns": 314671493650, "stddev_ns": 36379262, "avg_ts": 13.016750, "stddev_ts": 0.001504, "samples_ns": [ 314711983996, 314651600935, 314642828707, 314710181871, 314640872745 ],"samples_ts": [ 13.0151, 13.0176, 13.0179, 13.0151, 13.018 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-15T00:26:37Z", "avg_ns": 687690321972, "stddev_ns": 23988073, "avg_ts": 11.912339, "stddev_ts": 0.000415, "samples_ns": [ 687664147291, 687720473892, 687669999401, 687689603187, 687707386091 ],"samples_ts": [ 11.9128, 11.9118, 11.9127, 11.9124, 11.912 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:23:57Z", "avg_ns": 70287444, "stddev_ns": 204974, "avg_ts": 14.227389, "stddev_ts": 0.041417, "samples_ns": [ 70387500, 70208594, 70135627, 70597956, 70107543 ],"samples_ts": [ 14.2071, 14.2433, 14.2581, 14.1647, 14.2638 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:23:59Z", "avg_ns": 74821713, "stddev_ns": 219794, "avg_ts": 26.730393, "stddev_ts": 0.078453, "samples_ns": [ 75125646, 74796758, 74599848, 74636016, 74950297 ],"samples_ts": [ 26.6221, 26.7391, 26.8097, 26.7967, 26.6844 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:02Z", "avg_ns": 97921348, "stddev_ns": 1227398, "avg_ts": 40.854247, "stddev_ts": 0.512288, "samples_ns": [ 96734556, 99196153, 96629589, 99070257, 97976189 ],"samples_ts": [ 41.3503, 40.3241, 41.3952, 40.3754, 40.8262 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:04Z", "avg_ns": 183043456, "stddev_ns": 5476904, "avg_ts": 43.737085, "stddev_ts": 1.321023, "samples_ns": [ 185200970, 188880196, 175871703, 178792253, 186472160 ],"samples_ts": [ 43.1963, 42.3549, 45.4877, 44.7447, 42.9018 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:07Z", "avg_ns": 317556443, "stddev_ns": 639803, "avg_ts": 50.384907, "stddev_ts": 0.101238, "samples_ns": [ 318686878, 317255778, 317359633, 317118671, 317361256 ],"samples_ts": [ 50.206, 50.4325, 50.416, 50.4543, 50.4157 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:11Z", "avg_ns": 346940173, "stddev_ns": 1693173, "avg_ts": 92.236673, "stddev_ts": 0.448320, "samples_ns": [ 345704775, 346488779, 347301376, 345514077, 349691860 ],"samples_ts": [ 92.5645, 92.3551, 92.139, 92.6156, 91.5091 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:15Z", "avg_ns": 459907478, "stddev_ns": 1250302, "avg_ts": 139.159247, "stddev_ts": 0.378475, "samples_ns": [ 458860688, 460773495, 458345661, 460306056, 461251493 ],"samples_ts": [ 139.476, 138.897, 139.633, 139.038, 138.753 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:19Z", "avg_ns": 770803496, "stddev_ns": 1905393, "avg_ts": 166.061294, "stddev_ts": 0.410736, "samples_ns": [ 769614315, 768175541, 772239540, 771188254, 772799834 ],"samples_ts": [ 166.317, 166.629, 165.752, 165.978, 165.632 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:26Z", "avg_ns": 1582850001, "stddev_ns": 3700654, "avg_ts": 161.734289, "stddev_ts": 0.378345, "samples_ns": [ 1584260430, 1586593195, 1578598348, 1579213483, 1585584549 ],"samples_ts": [ 161.59, 161.352, 162.169, 162.106, 161.455 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:24:37Z", "avg_ns": 4280820086, "stddev_ns": 6986581, "avg_ts": 119.603506, "stddev_ts": 0.195177, "samples_ns": [ 4272242634, 4276283983, 4285130050, 4289900180, 4280543583 ],"samples_ts": [ 119.843, 119.73, 119.483, 119.35, 119.611 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:25:05Z", "avg_ns": 8636938331, "stddev_ns": 19469923, "avg_ts": 118.561013, "stddev_ts": 0.267013, "samples_ns": [ 8615822191, 8641809523, 8666033984, 8638179937, 8622846020 ],"samples_ts": [ 118.851, 118.494, 118.162, 118.543, 118.754 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:25:59Z", "avg_ns": 17718629922, "stddev_ns": 14617201, "avg_ts": 115.584620, "stddev_ts": 0.095365, "samples_ns": [ 17735839047, 17706586295, 17723391970, 17726733135, 17700599163 ],"samples_ts": [ 115.472, 115.663, 115.554, 115.532, 115.702 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:27:47Z", "avg_ns": 29612282966, "stddev_ns": 19078795, "avg_ts": 138.321026, "stddev_ts": 0.089051, "samples_ns": [ 29596247531, 29612197815, 29603362089, 29644872368, 29604735031 ],"samples_ts": [ 138.396, 138.321, 138.363, 138.169, 138.356 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T01:30:46Z", "avg_ns": 81502241075, "stddev_ns": 56906114, "avg_ts": 100.512613, "stddev_ts": 0.070196, "samples_ns": [ 81459661081, 81531070681, 81532856601, 81425877176, 81561739837 ],"samples_ts": [ 100.565, 100.477, 100.475, 100.607, 100.439 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-15T01:38:57Z", "avg_ns": 70232343, "stddev_ns": 157519, "avg_ts": 14.238511, "stddev_ts": 0.031828, "samples_ns": [ 70071279, 70300149, 70450422, 70249935, 70089934 ],"samples_ts": [ 14.2712, 14.2247, 14.1944, 14.2349, 14.2674 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-15T01:38:59Z", "avg_ns": 140072645, "stddev_ns": 440807, "avg_ts": 14.278418, "stddev_ts": 0.044898, "samples_ns": [ 139563427, 140656644, 140331492, 140069650, 139742014 ],"samples_ts": [ 14.3304, 14.219, 14.252, 14.2786, 14.3121 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-15T01:39:02Z", "avg_ns": 280506535, "stddev_ns": 365651, "avg_ts": 14.259937, "stddev_ts": 0.018556, "samples_ns": [ 281050824, 280684284, 280214810, 280410018, 280172741 ],"samples_ts": [ 14.2323, 14.2509, 14.2748, 14.2648, 14.2769 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-15T01:39:05Z", "avg_ns": 560104088, "stddev_ns": 521759, "avg_ts": 14.283069, "stddev_ts": 0.013285, "samples_ns": [ 560703645, 560198034, 560299705, 559283613, 560035447 ],"samples_ts": [ 14.2678, 14.2807, 14.2781, 14.304, 14.2848 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-15T01:39:10Z", "avg_ns": 1119678396, "stddev_ns": 1365267, "avg_ts": 14.289835, "stddev_ts": 0.017423, "samples_ns": [ 1119458990, 1117812564, 1120091947, 1119428409, 1121600070 ],"samples_ts": [ 14.2926, 14.3137, 14.2845, 14.293, 14.2653 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-15T01:39:17Z", "avg_ns": 2240021872, "stddev_ns": 1812101, "avg_ts": 14.285582, "stddev_ts": 0.011551, "samples_ns": [ 2241699218, 2242004937, 2237730565, 2239643966, 2239030677 ],"samples_ts": [ 14.2749, 14.2729, 14.3002, 14.288, 14.2919 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-15T01:39:31Z", "avg_ns": 4479478881, "stddev_ns": 3071925, "avg_ts": 14.287382, "stddev_ts": 0.009795, "samples_ns": [ 4482975097, 4482225825, 4477554488, 4475749372, 4478889625 ],"samples_ts": [ 14.2762, 14.2786, 14.2935, 14.2993, 14.2893 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-15T01:39:55Z", "avg_ns": 8954158612, "stddev_ns": 1983102, "avg_ts": 14.295034, "stddev_ts": 0.003160, "samples_ns": [ 8956630225, 8953632763, 8955822807, 8952297786, 8952409482 ],"samples_ts": [ 14.2911, 14.2959, 14.2924, 14.298, 14.2978 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-15T01:40:42Z", "avg_ns": 17910718506, "stddev_ns": 7304477, "avg_ts": 14.293119, "stddev_ts": 0.005828, "samples_ns": [ 17908239784, 17914416254, 17910730134, 17900286376, 17919919985 ],"samples_ts": [ 14.2951, 14.2902, 14.2931, 14.3014, 14.2858 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-15T01:42:13Z", "avg_ns": 35863308503, "stddev_ns": 8003945, "avg_ts": 14.276430, "stddev_ts": 0.003185, "samples_ns": [ 35871598683, 35864447409, 35856160356, 35870301787, 35854034283 ],"samples_ts": [ 14.2731, 14.276, 14.2793, 14.2736, 14.2801 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-15T01:45:14Z", "avg_ns": 72232047341, "stddev_ns": 14293323, "avg_ts": 14.176533, "stddev_ts": 0.002805, "samples_ns": [ 72239881164, 72234723430, 72224529222, 72249088372, 72212014520 ],"samples_ts": [ 14.175, 14.176, 14.178, 14.1732, 14.1805 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-15T01:51:17Z", "avg_ns": 146129629101, "stddev_ns": 10144913, "avg_ts": 14.014954, "stddev_ts": 0.000973, "samples_ns": [ 146129639991, 146113413100, 146129584590, 146134865035, 146140642789 ],"samples_ts": [ 14.015, 14.0165, 14.015, 14.0145, 14.0139 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-15T02:03:30Z", "avg_ns": 300081332220, "stddev_ns": 21887514, "avg_ts": 13.649633, "stddev_ts": 0.000995, "samples_ns": [ 300094613177, 300044649742, 300083522339, 300100990728, 300082885115 ],"samples_ts": [ 13.649, 13.6513, 13.6495, 13.6487, 13.6496 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-15T02:28:32Z", "avg_ns": 628413552641, "stddev_ns": 31666988, "avg_ts": 13.036002, "stddev_ts": 0.000657, "samples_ns": [ 628393674464, 628434989213, 628401809166, 628457151611, 628380138752 ],"samples_ts": [ 13.0364, 13.0356, 13.0362, 13.0351, 13.0367 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:20:56Z", "avg_ns": 73437635, "stddev_ns": 185482, "avg_ts": 13.617066, "stddev_ts": 0.034370, "samples_ns": [ 73515169, 73494039, 73237988, 73262815, 73678165 ],"samples_ts": [ 13.6026, 13.6065, 13.6541, 13.6495, 13.5725 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:20:59Z", "avg_ns": 86881199, "stddev_ns": 324727, "avg_ts": 23.020198, "stddev_ts": 0.086120, "samples_ns": [ 87086936, 87038234, 87210619, 86592326, 86477881 ],"samples_ts": [ 22.9656, 22.9784, 22.933, 23.0967, 23.1273 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:21:01Z", "avg_ns": 105889843, "stddev_ns": 1222138, "avg_ts": 37.779071, "stddev_ts": 0.429546, "samples_ns": [ 105382484, 108063495, 105138596, 105367335, 105497309 ],"samples_ts": [ 37.957, 37.0153, 38.045, 37.9624, 37.9157 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:21:04Z", "avg_ns": 171813713, "stddev_ns": 1316060, "avg_ts": 46.564224, "stddev_ts": 0.353666, "samples_ns": [ 170805668, 174076338, 171815427, 171151889, 171219246 ],"samples_ts": [ 46.8369, 45.9568, 46.5616, 46.7421, 46.7237 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:21:07Z", "avg_ns": 150478628, "stddev_ns": 1424049, "avg_ts": 106.335074, "stddev_ts": 1.014790, "samples_ns": [ 151255721, 150658659, 148114766, 150512003, 151851992 ],"samples_ts": [ 105.781, 106.2, 108.024, 106.304, 105.366 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:21:10Z", "avg_ns": 209837675, "stddev_ns": 1483523, "avg_ts": 152.504879, "stddev_ts": 1.069524, "samples_ns": [ 212412925, 209418134, 209610747, 208669046, 209077524 ],"samples_ts": [ 150.65, 152.804, 152.664, 153.353, 153.053 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:21:13Z", "avg_ns": 2470362529, "stddev_ns": 4452610, "avg_ts": 25.907196, "stddev_ts": 0.046739, "samples_ns": [ 2475511583, 2470748995, 2469872572, 2463386543, 2472292954 ],"samples_ts": [ 25.8532, 25.9031, 25.9123, 25.9805, 25.8869 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:21:30Z", "avg_ns": 3956386540, "stddev_ns": 19340638, "avg_ts": 32.353371, "stddev_ts": 0.157891, "samples_ns": [ 3935037437, 3958933334, 3984699947, 3961302076, 3941959910 ],"samples_ts": [ 32.5283, 32.3319, 32.1229, 32.3126, 32.4712 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:21:56Z", "avg_ns": 4780427652, "stddev_ns": 11932328, "avg_ts": 53.551962, "stddev_ts": 0.134032, "samples_ns": [ 4759972664, 4780146186, 4789435716, 4787028265, 4785555432 ],"samples_ts": [ 53.7818, 53.5548, 53.451, 53.4779, 53.4943 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:22:27Z", "avg_ns": 8671421380, "stddev_ns": 46480410, "avg_ts": 59.045889, "stddev_ts": 0.316914, "samples_ns": [ 8603580529, 8685024442, 8657667924, 8731433443, 8679400563 ],"samples_ts": [ 59.5101, 58.9521, 59.1383, 58.6387, 58.9902 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:23:20Z", "avg_ns": 16811739156, "stddev_ns": 74405803, "avg_ts": 60.910773, "stddev_ts": 0.269333, "samples_ns": [ 16920027870, 16787234759, 16831344538, 16805259886, 16714828727 ],"samples_ts": [ 60.52, 60.9987, 60.8389, 60.9333, 61.263 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:25:03Z", "avg_ns": 35719789294, "stddev_ns": 67991552, "avg_ts": 57.335331, "stddev_ts": 0.109345, "samples_ns": [ 35604209884, 35783467850, 35743780560, 35741251459, 35726236718 ],"samples_ts": [ 57.5213, 57.2331, 57.2967, 57.3007, 57.3248 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:28:40Z", "avg_ns": 75717149113, "stddev_ns": 382091204, "avg_ts": 54.097169, "stddev_ts": 0.272881, "samples_ns": [ 75321953407, 75352285594, 75752190582, 76203383162, 75955932824 ],"samples_ts": [ 54.3799, 54.358, 54.071, 53.7509, 53.926 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T03:36:16Z", "avg_ns": 166799729288, "stddev_ns": 344642571, "avg_ts": 49.112958, "stddev_ts": 0.101728, "samples_ns": [ 166197060366, 166975249790, 167055543523, 166863296907, 166907495858 ],"samples_ts": [ 49.2909, 49.0612, 49.0376, 49.0941, 49.0811 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-15T03:52:58Z", "avg_ns": 73307270, "stddev_ns": 112051, "avg_ts": 13.641237, "stddev_ts": 0.020822, "samples_ns": [ 73313211, 73457533, 73153421, 73262566, 73349620 ],"samples_ts": [ 13.6401, 13.6133, 13.6699, 13.6495, 13.6333 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-15T03:53:01Z", "avg_ns": 146424359, "stddev_ns": 212386, "avg_ts": 13.658953, "stddev_ts": 0.019808, "samples_ns": [ 146542235, 146156940, 146384418, 146713366, 146324836 ],"samples_ts": [ 13.6479, 13.6839, 13.6627, 13.632, 13.6682 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-15T03:53:03Z", "avg_ns": 292944909, "stddev_ns": 260147, "avg_ts": 13.654453, "stddev_ts": 0.012096, "samples_ns": [ 293305756, 292886708, 292652147, 293098365, 292781571 ],"samples_ts": [ 13.6376, 13.6572, 13.6681, 13.6473, 13.6621 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-15T03:53:07Z", "avg_ns": 586700722, "stddev_ns": 242087, "avg_ts": 13.635574, "stddev_ts": 0.005610, "samples_ns": [ 586628072, 586649031, 587112933, 586640304, 586473271 ],"samples_ts": [ 13.6373, 13.6368, 13.626, 13.637, 13.6409 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-15T03:53:12Z", "avg_ns": 1173829052, "stddev_ns": 501203, "avg_ts": 13.630607, "stddev_ts": 0.005803, "samples_ns": [ 1172948736, 1173997687, 1173940510, 1174098958, 1174159372 ],"samples_ts": [ 13.6408, 13.6286, 13.6293, 13.6275, 13.6268 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-15T03:53:20Z", "avg_ns": 2347500128, "stddev_ns": 828992, "avg_ts": 13.631524, "stddev_ts": 0.004801, "samples_ns": [ 2346972636, 2348711415, 2347461659, 2347801833, 2346553100 ],"samples_ts": [ 13.6346, 13.6245, 13.6317, 13.6298, 13.637 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-15T03:53:34Z", "avg_ns": 4694547443, "stddev_ns": 2036586, "avg_ts": 13.632839, "stddev_ts": 0.005908, "samples_ns": [ 4697471993, 4695707950, 4693156039, 4692459363, 4693941873 ],"samples_ts": [ 13.6243, 13.6295, 13.6369, 13.6389, 13.6346 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-15T03:53:59Z", "avg_ns": 9413471946, "stddev_ns": 1072621, "avg_ts": 13.597534, "stddev_ts": 0.001549, "samples_ns": [ 9414427017, 9413729882, 9412433259, 9412260217, 9414509355 ],"samples_ts": [ 13.5962, 13.5972, 13.599, 13.5993, 13.596 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-15T03:54:49Z", "avg_ns": 18948792627, "stddev_ns": 2119166, "avg_ts": 13.510096, "stddev_ts": 0.001509, "samples_ns": [ 18952200207, 18948682363, 18947445030, 18948954671, 18946680865 ],"samples_ts": [ 13.5077, 13.5102, 13.5111, 13.51, 13.5116 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-15T03:56:25Z", "avg_ns": 38409141270, "stddev_ns": 2380146, "avg_ts": 13.330160, "stddev_ts": 0.000825, "samples_ns": [ 38407895852, 38407635162, 38413308338, 38408879483, 38407987516 ],"samples_ts": [ 13.3306, 13.3307, 13.3287, 13.3303, 13.3306 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-15T03:59:40Z", "avg_ns": 78697543623, "stddev_ns": 23047431, "avg_ts": 13.011843, "stddev_ts": 0.003810, "samples_ns": [ 78694541031, 78673727578, 78677615847, 78715517076, 78726316586 ],"samples_ts": [ 13.0123, 13.0158, 13.0151, 13.0089, 13.0071 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-15T04:06:15Z", "avg_ns": 164922748738, "stddev_ns": 41207707, "avg_ts": 12.417936, "stddev_ts": 0.003104, "samples_ns": [ 164940884147, 164936893987, 164948680004, 164937778451, 164849507103 ],"samples_ts": [ 12.4166, 12.4169, 12.416, 12.4168, 12.4235 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-15T04:20:02Z", "avg_ns": 356817441575, "stddev_ns": 19257585, "avg_ts": 11.479260, "stddev_ts": 0.000619, "samples_ns": [ 356840636316, 356790809564, 356807983108, 356818348469, 356829430421 ],"samples_ts": [ 11.4785, 11.4801, 11.4796, 11.4792, 11.4789 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-15T04:49:48Z", "avg_ns": 816553099946, "stddev_ns": 35138995, "avg_ts": 10.032416, "stddev_ts": 0.000432, "samples_ns": [ 816579882439, 816564253335, 816579066397, 816494884237, 816547413323 ],"samples_ts": [ 10.0321, 10.0323, 10.0321, 10.0331, 10.0325 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:57:53Z", "avg_ns": 75907735, "stddev_ns": 69318, "avg_ts": 13.173896, "stddev_ts": 0.011841, "samples_ns": [ 75832683, 75978106, 75958199, 75837762, 75931929 ],"samples_ts": [ 13.1869, 13.1617, 13.1651, 13.186, 13.1697 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:57:55Z", "avg_ns": 90374791, "stddev_ns": 374043, "avg_ts": 22.130367, "stddev_ts": 0.091401, "samples_ns": [ 90000564, 90651929, 90157980, 90181053, 90882432 ],"samples_ts": [ 22.2221, 22.0624, 22.1833, 22.1776, 22.0065 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:57:58Z", "avg_ns": 108856587, "stddev_ns": 1338363, "avg_ts": 36.749973, "stddev_ts": 0.445239, "samples_ns": [ 108653526, 111199352, 108044240, 107976593, 108409227 ],"samples_ts": [ 36.8143, 35.9714, 37.0219, 37.0451, 36.8972 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:58:01Z", "avg_ns": 175200105, "stddev_ns": 1208248, "avg_ts": 45.663800, "stddev_ts": 0.313145, "samples_ns": [ 174540655, 177181047, 175102861, 175188071, 173987895 ],"samples_ts": [ 45.8346, 45.1516, 45.6874, 45.6652, 45.9802 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:58:04Z", "avg_ns": 160357395, "stddev_ns": 1987020, "avg_ts": 99.789333, "stddev_ts": 1.231558, "samples_ns": [ 159678117, 159001515, 158284728, 161795216, 163027402 ],"samples_ts": [ 100.202, 100.628, 101.084, 98.8904, 98.143 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:58:07Z", "avg_ns": 226219536, "stddev_ns": 2211389, "avg_ts": 141.466278, "stddev_ts": 1.376960, "samples_ns": [ 224546861, 229438596, 224004561, 227350500, 225757166 ],"samples_ts": [ 142.509, 139.471, 142.854, 140.752, 141.745 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:58:10Z", "avg_ns": 2456227153, "stddev_ns": 10623120, "avg_ts": 26.056612, "stddev_ts": 0.112620, "samples_ns": [ 2460486624, 2471208168, 2452062339, 2442450912, 2454927724 ],"samples_ts": [ 26.0111, 25.8983, 26.1005, 26.2032, 26.07 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:58:27Z", "avg_ns": 4124784503, "stddev_ns": 27347066, "avg_ts": 31.033016, "stddev_ts": 0.205781, "samples_ns": [ 4125729357, 4097466911, 4150822062, 4096967552, 4152936636 ],"samples_ts": [ 31.0248, 31.2388, 30.8373, 31.2426, 30.8216 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:58:54Z", "avg_ns": 5156433709, "stddev_ns": 16183931, "avg_ts": 49.647108, "stddev_ts": 0.156127, "samples_ns": [ 5157112144, 5174956971, 5162668642, 5130644416, 5156786374 ],"samples_ts": [ 49.6402, 49.469, 49.5868, 49.8963, 49.6433 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T05:59:27Z", "avg_ns": 9319253496, "stddev_ns": 40120076, "avg_ts": 54.940836, "stddev_ts": 0.236175, "samples_ns": [ 9295096846, 9360960175, 9364972915, 9284180728, 9291056820 ],"samples_ts": [ 55.0828, 54.6952, 54.6718, 55.1476, 55.1068 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T06:00:25Z", "avg_ns": 20121088766, "stddev_ns": 45793285, "avg_ts": 50.892089, "stddev_ts": 0.115777, "samples_ns": [ 20169183853, 20108756607, 20082765079, 20075194487, 20169543804 ],"samples_ts": [ 50.7705, 50.9231, 50.989, 51.0082, 50.7696 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T06:02:28Z", "avg_ns": 41974798678, "stddev_ns": 54627418, "avg_ts": 48.791247, "stddev_ts": 0.063472, "samples_ns": [ 42024945265, 41952021744, 41930290671, 42041570049, 41925165665 ],"samples_ts": [ 48.733, 48.8177, 48.843, 48.7137, 48.8489 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T06:06:42Z", "avg_ns": 94964653470, "stddev_ns": 311696817, "avg_ts": 43.132209, "stddev_ts": 0.141404, "samples_ns": [ 94746896672, 94692858957, 94777034126, 95265502303, 95340975293 ],"samples_ts": [ 43.231, 43.2556, 43.2172, 42.9956, 42.9616 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T06:16:14Z", "avg_ns": 218671281476, "stddev_ns": 295293069, "avg_ts": 37.462679, "stddev_ts": 0.050656, "samples_ns": [ 218171667294, 218954891703, 218776077893, 218698808460, 218754962031 ],"samples_ts": [ 37.5484, 37.4141, 37.4447, 37.4579, 37.4483 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-15T06:38:07Z", "avg_ns": 75957582, "stddev_ns": 193485, "avg_ts": 13.165311, "stddev_ts": 0.033510, "samples_ns": [ 75985747, 76001718, 75684200, 75897271, 76218976 ],"samples_ts": [ 13.1604, 13.1576, 13.2128, 13.1757, 13.1201 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-15T06:38:10Z", "avg_ns": 151682988, "stddev_ns": 224792, "avg_ts": 13.185417, "stddev_ts": 0.019542, "samples_ns": [ 151777450, 151299952, 151804721, 151858993, 151673826 ],"samples_ts": [ 13.1772, 13.2188, 13.1748, 13.1701, 13.1862 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-15T06:38:13Z", "avg_ns": 303572728, "stddev_ns": 284976, "avg_ts": 13.176423, "stddev_ts": 0.012373, "samples_ns": [ 303242463, 303287749, 303704501, 303801775, 303827152 ],"samples_ts": [ 13.1908, 13.1888, 13.1707, 13.1665, 13.1654 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-15T06:38:17Z", "avg_ns": 607690364, "stddev_ns": 332511, "avg_ts": 13.164602, "stddev_ts": 0.007176, "samples_ns": [ 607762248, 607157451, 607669714, 607802734, 608059676 ],"samples_ts": [ 13.163, 13.1762, 13.165, 13.1622, 13.1566 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-15T06:38:22Z", "avg_ns": 1214666932, "stddev_ns": 616095, "avg_ts": 13.172338, "stddev_ts": 0.006658, "samples_ns": [ 1213942111, 1215634521, 1214451999, 1214638880, 1214667153 ],"samples_ts": [ 13.1802, 13.1619, 13.1747, 13.1726, 13.1723 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-15T06:38:29Z", "avg_ns": 2430601997, "stddev_ns": 328329, "avg_ts": 13.165463, "stddev_ts": 0.001738, "samples_ns": [ 2430374041, 2430796445, 2430363171, 2431075701, 2430400631 ],"samples_ts": [ 13.1667, 13.1644, 13.1668, 13.1629, 13.1666 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-15T06:38:44Z", "avg_ns": 4860566335, "stddev_ns": 1551547, "avg_ts": 13.167191, "stddev_ts": 0.004195, "samples_ns": [ 4862632836, 4860093903, 4858358642, 4860741782, 4861004516 ],"samples_ts": [ 13.1616, 13.1685, 13.1732, 13.1667, 13.166 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-15T06:39:10Z", "avg_ns": 9726327037, "stddev_ns": 1141437, "avg_ts": 13.160158, "stddev_ts": 0.001533, "samples_ns": [ 9725401639, 9726698417, 9728137383, 9725507960, 9725889790 ],"samples_ts": [ 13.1614, 13.1597, 13.1577, 13.1613, 13.1607 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-15T06:40:01Z", "avg_ns": 19430371140, "stddev_ns": 2084152, "avg_ts": 13.175250, "stddev_ts": 0.001412, "samples_ns": [ 19430891937, 19427350452, 19433046120, 19430903786, 19429663406 ],"samples_ts": [ 13.1749, 13.1773, 13.1734, 13.1749, 13.1757 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-15T06:41:40Z", "avg_ns": 38836067030, "stddev_ns": 6251628, "avg_ts": 13.183622, "stddev_ts": 0.002122, "samples_ns": [ 38844251231, 38838967727, 38835145068, 38834756743, 38827214381 ],"samples_ts": [ 13.1808, 13.1826, 13.1839, 13.1841, 13.1866 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-15T06:44:56Z", "avg_ns": 78129875723, "stddev_ns": 8536785, "avg_ts": 13.106382, "stddev_ts": 0.001432, "samples_ns": [ 78142588422, 78127988922, 78123998282, 78121101102, 78133701888 ],"samples_ts": [ 13.1042, 13.1067, 13.1074, 13.1079, 13.1057 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-15T06:51:29Z", "avg_ns": 161087827541, "stddev_ns": 9777219, "avg_ts": 12.713562, "stddev_ts": 0.000771, "samples_ns": [ 161074049821, 161084633299, 161100019858, 161086953494, 161093481236 ],"samples_ts": [ 12.7146, 12.7138, 12.7126, 12.7136, 12.7131 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-15T07:04:56Z", "avg_ns": 341650239050, "stddev_ns": 22287186, "avg_ts": 11.988869, "stddev_ts": 0.000782, "samples_ns": [ 341684284455, 341660869146, 341630859861, 341640695849, 341634485939 ],"samples_ts": [ 11.9877, 11.9885, 11.9895, 11.9892, 11.9894 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-15T07:33:27Z", "avg_ns": 764584891642, "stddev_ns": 16224988, "avg_ts": 10.714311, "stddev_ts": 0.000227, "samples_ns": [ 764598241808, 764591242351, 764561551740, 764598511215, 764574911099 ],"samples_ts": [ 10.7141, 10.7142, 10.7146, 10.7141, 10.7145 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:12Z", "avg_ns": 73214990, "stddev_ns": 224711, "avg_ts": 13.658508, "stddev_ts": 0.041821, "samples_ns": [ 73204657, 73544967, 73014620, 73305837, 73004872 ],"samples_ts": [ 13.6603, 13.5971, 13.6959, 13.6415, 13.6977 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:15Z", "avg_ns": 87018882, "stddev_ns": 283706, "avg_ts": 22.983712, "stddev_ts": 0.074837, "samples_ns": [ 87367865, 87240525, 86665244, 86880839, 86939941 ],"samples_ts": [ 22.8917, 22.9251, 23.0773, 23.02, 23.0044 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:17Z", "avg_ns": 105197158, "stddev_ns": 658286, "avg_ts": 38.025025, "stddev_ts": 0.236661, "samples_ns": [ 104758618, 106277793, 105052431, 104610670, 105286280 ],"samples_ts": [ 38.183, 37.6372, 38.0762, 38.237, 37.9917 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:20Z", "avg_ns": 218728632, "stddev_ns": 1284343, "avg_ts": 36.576003, "stddev_ts": 0.213293, "samples_ns": [ 218401434, 218517361, 220964911, 217838696, 217920760 ],"samples_ts": [ 36.6298, 36.6104, 36.2048, 36.7244, 36.7106 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:23Z", "avg_ns": 198126223, "stddev_ns": 2649265, "avg_ts": 80.768221, "stddev_ts": 1.086491, "samples_ns": [ 199681683, 201099197, 197098047, 198570655, 194181536 ],"samples_ts": [ 80.1275, 79.5627, 81.1779, 80.5759, 82.3971 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:27Z", "avg_ns": 259245540, "stddev_ns": 2399829, "avg_ts": 123.443603, "stddev_ts": 1.147866, "samples_ns": [ 260924760, 261572438, 257842027, 260117293, 255771185 ],"samples_ts": [ 122.641, 122.337, 124.107, 123.021, 125.112 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:30Z", "avg_ns": 733537274, "stddev_ns": 693076, "avg_ts": 87.248526, "stddev_ts": 0.082428, "samples_ns": [ 733749960, 734042589, 733019006, 734253136, 732621680 ],"samples_ts": [ 87.2232, 87.1884, 87.3102, 87.1634, 87.3575 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:37Z", "avg_ns": 823043286, "stddev_ns": 789127, "avg_ts": 155.520488, "stddev_ts": 0.148807, "samples_ns": [ 824400587, 822999323, 822442397, 822803026, 822571100 ],"samples_ts": [ 155.264, 155.529, 155.634, 155.566, 155.61 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:44Z", "avg_ns": 1208842608, "stddev_ns": 3356500, "avg_ts": 211.774119, "stddev_ts": 0.587767, "samples_ns": [ 1213031389, 1211497838, 1207468587, 1207451615, 1204763614 ],"samples_ts": [ 211.042, 211.309, 212.014, 212.017, 212.49 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:37:53Z", "avg_ns": 1637958641, "stddev_ns": 8167300, "avg_ts": 312.590443, "stddev_ts": 1.563722, "samples_ns": [ 1644734124, 1641111829, 1644294582, 1625436381, 1634216293 ],"samples_ts": [ 311.297, 311.984, 311.38, 314.992, 313.3 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:38:05Z", "avg_ns": 3356629081, "stddev_ns": 7265584, "avg_ts": 305.069108, "stddev_ts": 0.660763, "samples_ns": [ 3365470920, 3358009953, 3359997203, 3353533010, 3346134319 ],"samples_ts": [ 304.266, 304.943, 304.762, 305.35, 306.025 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:38:28Z", "avg_ns": 7224506993, "stddev_ns": 7832909, "avg_ts": 283.479818, "stddev_ts": 0.307375, "samples_ns": [ 7214625166, 7228827781, 7218731189, 7226209195, 7234141635 ],"samples_ts": [ 283.868, 283.31, 283.706, 283.413, 283.102 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:39:13Z", "avg_ns": 16270238594, "stddev_ns": 12989788, "avg_ts": 251.748127, "stddev_ts": 0.200835, "samples_ns": [ 16265614058, 16261040786, 16273111280, 16291535164, 16259891685 ],"samples_ts": [ 251.82, 251.89, 251.704, 251.419, 251.908 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T08:40:53Z", "avg_ns": 39940793963, "stddev_ns": 44056384, "avg_ts": 205.103784, "stddev_ts": 0.226282, "samples_ns": [ 39995842608, 39963320911, 39920355509, 39945208928, 39879241861 ],"samples_ts": [ 204.821, 204.988, 205.209, 205.081, 205.42 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-15T08:44:55Z", "avg_ns": 73321356, "stddev_ns": 130584, "avg_ts": 13.638626, "stddev_ts": 0.024306, "samples_ns": [ 73416006, 73437557, 73202935, 73392301, 73157981 ],"samples_ts": [ 13.621, 13.617, 13.6607, 13.6254, 13.669 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-15T08:44:57Z", "avg_ns": 146549073, "stddev_ns": 101484, "avg_ts": 13.647311, "stddev_ts": 0.009317, "samples_ns": [ 146660400, 146616607, 146496561, 146564419, 146407382 ],"samples_ts": [ 13.6369, 13.641, 13.6522, 13.6459, 13.6605 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-15T08:45:00Z", "avg_ns": 293223897, "stddev_ns": 144530, "avg_ts": 13.641456, "stddev_ts": 0.006725, "samples_ns": [ 293369310, 293064658, 293073274, 293326680, 293285563 ],"samples_ts": [ 13.6347, 13.6489, 13.6485, 13.6367, 13.6386 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-15T08:45:03Z", "avg_ns": 586601509, "stddev_ns": 814537, "avg_ts": 13.637899, "stddev_ts": 0.018959, "samples_ns": [ 587093288, 585152340, 586877733, 586950159, 586934028 ],"samples_ts": [ 13.6265, 13.6717, 13.6315, 13.6298, 13.6302 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-15T08:45:08Z", "avg_ns": 1171907237, "stddev_ns": 372002, "avg_ts": 13.652959, "stddev_ts": 0.004307, "samples_ns": [ 1171354855, 1172055612, 1172363251, 1171952188, 1171810282 ],"samples_ts": [ 13.6594, 13.6512, 13.6476, 13.6524, 13.6541 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-15T08:45:16Z", "avg_ns": 2345687568, "stddev_ns": 399463, "avg_ts": 13.642056, "stddev_ts": 0.002289, "samples_ns": [ 2345143869, 2346126897, 2345437974, 2345919119, 2345809985 ],"samples_ts": [ 13.6452, 13.6395, 13.6435, 13.6407, 13.6413 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-15T08:45:30Z", "avg_ns": 4693359805, "stddev_ns": 2332520, "avg_ts": 13.636289, "stddev_ts": 0.006769, "samples_ns": [ 4696991201, 4694221589, 4692682210, 4691283366, 4691620663 ],"samples_ts": [ 13.6257, 13.6338, 13.6383, 13.6423, 13.6413 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-15T08:45:56Z", "avg_ns": 9415409650, "stddev_ns": 2065503, "avg_ts": 13.594736, "stddev_ts": 0.002980, "samples_ns": [ 9418664582, 9415769697, 9415248133, 9413274940, 9414090899 ],"samples_ts": [ 13.59, 13.5942, 13.595, 13.5978, 13.5966 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-15T08:46:45Z", "avg_ns": 18929018779, "stddev_ns": 1647335, "avg_ts": 13.524209, "stddev_ts": 0.001169, "samples_ns": [ 18930988708, 18930280797, 18928940094, 18927086896, 18927797404 ],"samples_ts": [ 13.5228, 13.5233, 13.5243, 13.5256, 13.5251 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-15T08:48:22Z", "avg_ns": 38453589546, "stddev_ns": 5950758, "avg_ts": 13.314752, "stddev_ts": 0.002058, "samples_ns": [ 38463606278, 38447900523, 38453409938, 38451477143, 38451553852 ],"samples_ts": [ 13.3113, 13.3167, 13.3148, 13.3155, 13.3155 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-15T08:51:36Z", "avg_ns": 78645783292, "stddev_ns": 10764992, "avg_ts": 13.020406, "stddev_ts": 0.001782, "samples_ns": [ 78651345214, 78629576941, 78650316203, 78656914392, 78640763712 ],"samples_ts": [ 13.0195, 13.0231, 13.0197, 13.0186, 13.0212 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-15T08:58:11Z", "avg_ns": 164775192674, "stddev_ns": 17936403, "avg_ts": 12.429056, "stddev_ts": 0.001353, "samples_ns": [ 164778514600, 164799471922, 164753297608, 164762584162, 164782095079 ],"samples_ts": [ 12.4288, 12.4272, 12.4307, 12.43, 12.4285 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-15T09:11:58Z", "avg_ns": 356647643908, "stddev_ns": 9733531, "avg_ts": 11.484725, "stddev_ts": 0.000312, "samples_ns": [ 356661456111, 356649974786, 356635246914, 356642672371, 356648869362 ],"samples_ts": [ 11.4843, 11.4846, 11.4851, 11.4849, 11.4847 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-15T09:41:43Z", "avg_ns": 816458088898, "stddev_ns": 38974880, "avg_ts": 10.033583, "stddev_ts": 0.000479, "samples_ns": [ 816486743482, 816394396509, 816451271417, 816490727990, 816467305093 ],"samples_ts": [ 10.0332, 10.0344, 10.0337, 10.0332, 10.0335 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:49:47Z", "avg_ns": 75916781, "stddev_ns": 86828, "avg_ts": 13.172332, "stddev_ts": 0.014995, "samples_ns": [ 76011357, 75967524, 75858991, 75947728, 75798307 ],"samples_ts": [ 13.1559, 13.1635, 13.1824, 13.167, 13.1929 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:49:50Z", "avg_ns": 90390860, "stddev_ns": 386977, "avg_ts": 22.126454, "stddev_ts": 0.094361, "samples_ns": [ 90485009, 91023471, 90088073, 90114814, 90242934 ],"samples_ts": [ 22.1031, 21.9724, 22.2005, 22.1939, 22.1624 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:49:53Z", "avg_ns": 108529953, "stddev_ns": 703294, "avg_ts": 36.857418, "stddev_ts": 0.237915, "samples_ns": [ 108209060, 109591208, 108107118, 107861367, 108881013 ],"samples_ts": [ 36.9655, 36.4993, 37.0003, 37.0846, 36.7374 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:49:55Z", "avg_ns": 175007787, "stddev_ns": 1381620, "avg_ts": 45.714517, "stddev_ts": 0.358658, "samples_ns": [ 175006150, 177273081, 174799522, 174396955, 173563229 ],"samples_ts": [ 45.7127, 45.1281, 45.7667, 45.8724, 46.0927 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:49:58Z", "avg_ns": 159209956, "stddev_ns": 1282014, "avg_ts": 100.501439, "stddev_ts": 0.809134, "samples_ns": [ 159282379, 157796135, 158064780, 160741511, 160164978 ],"samples_ts": [ 100.451, 101.397, 101.224, 99.5387, 99.897 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:50:01Z", "avg_ns": 226312026, "stddev_ns": 1560326, "avg_ts": 141.403080, "stddev_ts": 0.975398, "samples_ns": [ 227735973, 227923384, 226465905, 224666193, 224768675 ],"samples_ts": [ 140.514, 140.398, 141.302, 142.434, 142.369 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:50:04Z", "avg_ns": 711059693, "stddev_ns": 639698, "avg_ts": 90.006566, "stddev_ts": 0.080899, "samples_ns": [ 711085512, 711586113, 709996656, 711530589, 711099599 ],"samples_ts": [ 90.0032, 89.9399, 90.1413, 89.9469, 90.0015 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:50:11Z", "avg_ns": 823627559, "stddev_ns": 1844288, "avg_ts": 155.410673, "stddev_ts": 0.347730, "samples_ns": [ 823593053, 821447641, 826348413, 824187081, 822561607 ],"samples_ts": [ 155.417, 155.822, 154.898, 155.305, 155.611 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:50:18Z", "avg_ns": 1252844844, "stddev_ns": 2349121, "avg_ts": 204.335533, "stddev_ts": 0.382507, "samples_ns": [ 1252823285, 1251902745, 1250396204, 1256714640, 1252387348 ],"samples_ts": [ 204.338, 204.489, 204.735, 203.706, 204.41 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:50:27Z", "avg_ns": 1886614480, "stddev_ns": 3908131, "avg_ts": 271.386531, "stddev_ts": 0.562570, "samples_ns": [ 1880806914, 1891111594, 1889107418, 1886352572, 1885693905 ],"samples_ts": [ 272.224, 270.74, 271.027, 271.423, 271.518 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:50:40Z", "avg_ns": 4180748487, "stddev_ns": 6167257, "avg_ts": 244.932644, "stddev_ts": 0.361143, "samples_ns": [ 4183219900, 4173166192, 4189726703, 4178342424, 4179287217 ],"samples_ts": [ 244.788, 245.377, 244.407, 245.073, 245.018 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:51:08Z", "avg_ns": 9971718041, "stddev_ns": 10119947, "avg_ts": 205.381026, "stddev_ts": 0.208383, "samples_ns": [ 9979832649, 9967743285, 9984651921, 9960445631, 9965916719 ],"samples_ts": [ 205.214, 205.463, 205.115, 205.613, 205.5 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:52:10Z", "avg_ns": 27397767374, "stddev_ns": 35773050, "avg_ts": 149.501437, "stddev_ts": 0.195296, "samples_ns": [ 27370533928, 27349794110, 27411866698, 27426120684, 27430521454 ],"samples_ts": [ 149.65, 149.763, 149.424, 149.347, 149.323 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 8192, "n_gen": 0, "n_depth": 0, "test_time": "2025-07-15T10:54:56Z", "avg_ns": 83919230620, "stddev_ns": 32247004, "avg_ts": 97.617684, "stddev_ts": 0.037511, "samples_ns": [ 83872328079, 83928249679, 83915021740, 83918206647, 83962346958 ],"samples_ts": [ 97.6723, 97.6072, 97.6226, 97.6189, 97.5675 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-07-15T11:03:22Z", "avg_ns": 75932849, "stddev_ns": 209263, "avg_ts": 13.169611, "stddev_ts": 0.036240, "samples_ns": [ 76218771, 75634062, 75895083, 75978460, 75937873 ],"samples_ts": [ 13.1201, 13.2216, 13.1761, 13.1616, 13.1687 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-07-15T11:03:24Z", "avg_ns": 151728298, "stddev_ns": 216457, "avg_ts": 13.181478, "stddev_ts": 0.018743, "samples_ns": [ 151878090, 151731585, 151565372, 151995101, 151471346 ],"samples_ts": [ 13.1685, 13.1812, 13.1956, 13.1583, 13.2038 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-07-15T11:03:27Z", "avg_ns": 303600528, "stddev_ns": 270269, "avg_ts": 13.175216, "stddev_ts": 0.011712, "samples_ns": [ 303671192, 303162445, 303902816, 303649810, 303616379 ],"samples_ts": [ 13.1721, 13.1942, 13.1621, 13.1731, 13.1745 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-07-15T11:03:31Z", "avg_ns": 607742579, "stddev_ns": 276738, "avg_ts": 13.163470, "stddev_ts": 0.005983, "samples_ns": [ 607393809, 607891445, 607924187, 608004878, 607498577 ],"samples_ts": [ 13.171, 13.1602, 13.1595, 13.1578, 13.1688 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-07-15T11:03:36Z", "avg_ns": 1216023738, "stddev_ns": 494714, "avg_ts": 13.157640, "stddev_ts": 0.005333, "samples_ns": [ 1215542568, 1215925077, 1215579347, 1216600707, 1216470994 ],"samples_ts": [ 13.1628, 13.1587, 13.1624, 13.1514, 13.1528 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-07-15T11:03:44Z", "avg_ns": 2430679002, "stddev_ns": 1325014, "avg_ts": 13.165049, "stddev_ts": 0.007173, "samples_ns": [ 2429163066, 2429775277, 2432520588, 2431383060, 2430553020 ],"samples_ts": [ 13.1733, 13.1699, 13.1551, 13.1612, 13.1657 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-07-15T11:03:58Z", "avg_ns": 4859089779, "stddev_ns": 795238, "avg_ts": 13.171191, "stddev_ts": 0.002156, "samples_ns": [ 4859439460, 4858139229, 4858370164, 4859511161, 4859988881 ],"samples_ts": [ 13.1702, 13.1738, 13.1731, 13.17, 13.1688 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-07-15T11:04:25Z", "avg_ns": 9716661853, "stddev_ns": 1701894, "avg_ts": 13.173249, "stddev_ts": 0.002308, "samples_ns": [ 9717260561, 9717047419, 9718344814, 9716859450, 9713797021 ],"samples_ts": [ 13.1724, 13.1727, 13.171, 13.173, 13.1771 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-07-15T11:05:15Z", "avg_ns": 19433736372, "stddev_ns": 3058518, "avg_ts": 13.172969, "stddev_ts": 0.002069, "samples_ns": [ 19432339656, 19432249944, 19436088084, 19437705509, 19430298671 ],"samples_ts": [ 13.1739, 13.174, 13.1714, 13.1703, 13.1753 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-07-15T11:06:55Z", "avg_ns": 38853540058, "stddev_ns": 4827639, "avg_ts": 13.177693, "stddev_ts": 0.001636, "samples_ns": [ 38856242701, 38848194588, 38850022658, 38860214915, 38853025430 ],"samples_ts": [ 13.1768, 13.1795, 13.1789, 13.1754, 13.1779 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-07-15T11:10:11Z", "avg_ns": 78162284837, "stddev_ns": 6014137, "avg_ts": 13.100948, "stddev_ts": 0.001008, "samples_ns": [ 78166657511, 78168752937, 78157807381, 78154451676, 78163754681 ],"samples_ts": [ 13.1002, 13.0999, 13.1017, 13.1023, 13.1007 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-07-15T11:16:44Z", "avg_ns": 161122947838, "stddev_ns": 12704966, "avg_ts": 12.710790, "stddev_ts": 0.001002, "samples_ns": [ 161132361201, 161127462123, 161117432542, 161134080338, 161103402987 ],"samples_ts": [ 12.71, 12.7104, 12.7112, 12.7099, 12.7123 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-07-15T11:30:11Z", "avg_ns": 341525946055, "stddev_ns": 24044414, "avg_ts": 11.993232, "stddev_ts": 0.000844, "samples_ns": [ 341562912838, 341534271964, 341505023946, 341505376009, 341522145520 ],"samples_ts": [ 11.9919, 11.9929, 11.994, 11.994, 11.9934 ]}
{"build_commit": "a4575513", "build_number": 5863, "cpu_info": "AMD Eng Sample: 100-000001243-50_Y", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": true, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8192, "n_depth": 0, "test_time": "2025-07-15T11:58:41Z", "avg_ns": 765192525291, "stddev_ns": 35765083, "avg_ts": 10.705802, "stddev_ts": 0.000500, "samples_ns": [ 765144776911, 765174521068, 765201081294, 765201098061, 765241149122 ],"samples_ts": [ 10.7065, 10.7061, 10.7057, 10.7057, 10.7051 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:22Z", "avg_ns": 71572025, "stddev_ns": 62880, "avg_ts": 13.971948, "stddev_ts": 0.012273, "samples_ns": [ 71565103, 71660545, 71495091, 71538053, 71601333 ],"samples_ts": [ 13.9733, 13.9547, 13.987, 13.9786, 13.9662 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:24Z", "avg_ns": 82802613, "stddev_ns": 355550, "avg_ts": 24.154183, "stddev_ts": 0.103782, "samples_ns": [ 83115505, 82304401, 83171180, 82767648, 82654334 ],"samples_ts": [ 24.0629, 24.3, 24.0468, 24.164, 24.1972 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:27Z", "avg_ns": 97995171, "stddev_ns": 738523, "avg_ts": 40.820201, "stddev_ts": 0.309126, "samples_ns": [ 96832695, 98503655, 98733850, 98058032, 97847625 ],"samples_ts": [ 41.3084, 40.6076, 40.513, 40.7922, 40.8799 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:30Z", "avg_ns": 162084726, "stddev_ns": 3354958, "avg_ts": 49.373677, "stddev_ts": 1.013163, "samples_ns": [ 163572602, 167005855, 161736139, 158825485, 159283552 ],"samples_ts": [ 48.9079, 47.9025, 49.4633, 50.3698, 50.2249 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:33Z", "avg_ns": 140141466, "stddev_ns": 668689, "avg_ts": 114.172434, "stddev_ts": 0.546465, "samples_ns": [ 140300393, 140896109, 139075236, 140368361, 140067231 ],"samples_ts": [ 114.041, 113.559, 115.046, 113.986, 114.231 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:37Z", "avg_ns": 200004796, "stddev_ns": 3657708, "avg_ts": 160.038394, "stddev_ts": 2.886763, "samples_ns": [ 196850760, 205911854, 197140778, 200542621, 199577967 ],"samples_ts": [ 162.56, 155.406, 162.321, 159.567, 160.338 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:40Z", "avg_ns": 1029844303, "stddev_ns": 3010631, "avg_ts": 62.145742, "stddev_ts": 0.181803, "samples_ns": [ 1025604121, 1032441068, 1029228040, 1033047590, 1028900697 ],"samples_ts": [ 62.4022, 61.989, 62.1825, 61.9526, 62.2023 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:27:48Z", "avg_ns": 1432782848, "stddev_ns": 8693210, "avg_ts": 89.339257, "stddev_ts": 0.539894, "samples_ns": [ 1435811893, 1446372789, 1424113583, 1427895550, 1429720427 ],"samples_ts": [ 89.1482, 88.4972, 89.8805, 89.6424, 89.528 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:28:00Z", "avg_ns": 2706209122, "stddev_ns": 5279941, "avg_ts": 94.597560, "stddev_ts": 0.184582, "samples_ns": [ 2713252430, 2698923882, 2704645014, 2705570890, 2708653394 ],"samples_ts": [ 94.3517, 94.8526, 94.652, 94.6196, 94.5119 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:28:19Z", "avg_ns": 5342406877, "stddev_ns": 10730422, "avg_ts": 95.837263, "stddev_ts": 0.192723, "samples_ns": [ 5325685638, 5350116047, 5353163735, 5342997908, 5340071059 ],"samples_ts": [ 96.1379, 95.6989, 95.6444, 95.8264, 95.8789 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:28:53Z", "avg_ns": 10778644552, "stddev_ns": 33329964, "avg_ts": 95.003397, "stddev_ts": 0.294461, "samples_ns": [ 10792182203, 10787210894, 10724468457, 10775478386, 10813882824 ],"samples_ts": [ 94.8835, 94.9272, 95.4826, 95.0306, 94.6931 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:30:01Z", "avg_ns": 21829945261, "stddev_ns": 26066870, "avg_ts": 93.816192, "stddev_ts": 0.111927, "samples_ns": [ 21829045146, 21831069586, 21814293549, 21803367403, 21871950622 ],"samples_ts": [ 93.82, 93.8113, 93.8834, 93.9304, 93.6359 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T04:32:14Z", "avg_ns": 44962855160, "stddev_ns": 34291706, "avg_ts": 91.097460, "stddev_ts": 0.069495, "samples_ns": [ 44918707421, 44933815089, 44996313671, 44983852411, 44981587209 ],"samples_ts": [ 91.187, 91.1563, 91.0297, 91.0549, 91.0595 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T04:36:47Z", "avg_ns": 71729866, "stddev_ns": 367603, "avg_ts": 13.941485, "stddev_ts": 0.070997, "samples_ns": [ 71673994, 71499204, 71600476, 72374188, 71501469 ],"samples_ts": [ 13.9521, 13.9862, 13.9664, 13.8171, 13.9857 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T04:36:50Z", "avg_ns": 143323115, "stddev_ns": 567691, "avg_ts": 13.954657, "stddev_ts": 0.054991, "samples_ns": [ 144313254, 142935960, 143257698, 143121099, 142987568 ],"samples_ts": [ 13.8587, 13.9923, 13.9609, 13.9742, 13.9872 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T04:36:53Z", "avg_ns": 286076748, "stddev_ns": 462056, "avg_ts": 13.982291, "stddev_ts": 0.022540, "samples_ns": [ 286022924, 285896045, 286046359, 286834218, 285584196 ],"samples_ts": [ 13.9849, 13.9911, 13.9837, 13.9453, 14.0064 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T04:36:57Z", "avg_ns": 572507023, "stddev_ns": 825746, "avg_ts": 13.973651, "stddev_ts": 0.020172, "samples_ns": [ 572691288, 573193928, 571142490, 573096995, 572410416 ],"samples_ts": [ 13.9691, 13.9569, 14.007, 13.9592, 13.976 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T04:37:03Z", "avg_ns": 1145552310, "stddev_ns": 1125377, "avg_ts": 13.967073, "stddev_ts": 0.013714, "samples_ns": [ 1145822553, 1144025976, 1145194916, 1145575092, 1147143015 ],"samples_ts": [ 13.9638, 13.9857, 13.9714, 13.9668, 13.9477 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T04:37:11Z", "avg_ns": 2291965505, "stddev_ns": 1517552, "avg_ts": 13.961821, "stddev_ts": 0.009242, "samples_ns": [ 2291285944, 2293289136, 2290747519, 2290616938, 2293887988 ],"samples_ts": [ 13.966, 13.9538, 13.9692, 13.97, 13.9501 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T04:37:25Z", "avg_ns": 4590913253, "stddev_ns": 2332370, "avg_ts": 13.940584, "stddev_ts": 0.007075, "samples_ns": [ 4594685056, 4588263543, 4590386923, 4590738473, 4590492273 ],"samples_ts": [ 13.9291, 13.9486, 13.9422, 13.9411, 13.9419 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T04:37:50Z", "avg_ns": 9194356443, "stddev_ns": 1705360, "avg_ts": 13.921584, "stddev_ts": 0.002574, "samples_ns": [ 9197125501, 9193942209, 9194669140, 9193202395, 9192842974 ],"samples_ts": [ 13.9174, 13.9222, 13.9211, 13.9233, 13.9239 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T04:38:39Z", "avg_ns": 18500841178, "stddev_ns": 2131167, "avg_ts": 13.837209, "stddev_ts": 0.001587, "samples_ns": [ 18504205565, 18498925407, 18501392169, 18499238294, 18500444459 ],"samples_ts": [ 13.8347, 13.8386, 13.8368, 13.8384, 13.8375 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T04:40:14Z", "avg_ns": 37388074035, "stddev_ns": 4412705, "avg_ts": 13.694206, "stddev_ts": 0.001613, "samples_ns": [ 37387514423, 37384061783, 37391082394, 37393900834, 37383810745 ],"samples_ts": [ 13.6944, 13.6957, 13.6931, 13.6921, 13.6958 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T04:43:23Z", "avg_ns": 76471448013, "stddev_ns": 14137061, "avg_ts": 13.390619, "stddev_ts": 0.002475, "samples_ns": [ 76467849376, 76454691942, 76475985170, 76465948439, 76492765141 ],"samples_ts": [ 13.3912, 13.3936, 13.3898, 13.3916, 13.3869 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T04:49:48Z", "avg_ns": 160032555073, "stddev_ns": 7264044, "avg_ts": 12.797396, "stddev_ts": 0.000580, "samples_ns": [ 160032876769, 160036828997, 160029451764, 160022279192, 160041338644 ],"samples_ts": [ 12.7974, 12.7971, 12.7976, 12.7982, 12.7967 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T05:03:11Z", "avg_ns": 345904305092, "stddev_ns": 17406334, "avg_ts": 11.841425, "stddev_ts": 0.000596, "samples_ns": [ 345930783442, 345893469339, 345885065160, 345908938209, 345903269311 ],"samples_ts": [ 11.8405, 11.8418, 11.8421, 11.8413, 11.8415 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:03Z", "avg_ns": 72210685, "stddev_ns": 734303, "avg_ts": 13.849496, "stddev_ts": 0.138973, "samples_ns": [ 71960617, 71832986, 73517539, 71950949, 71791337 ],"samples_ts": [ 13.8965, 13.9212, 13.6022, 13.8984, 13.9293 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:06Z", "avg_ns": 84551793, "stddev_ns": 492235, "avg_ts": 23.654781, "stddev_ts": 0.137577, "samples_ns": [ 84546783, 83894970, 84378675, 84687738, 85250803 ],"samples_ts": [ 23.6555, 23.8393, 23.7027, 23.6162, 23.4602 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:09Z", "avg_ns": 102094242, "stddev_ns": 1127902, "avg_ts": 39.183305, "stddev_ts": 0.432131, "samples_ns": [ 101651917, 102709234, 101797562, 103642599, 100669901 ],"samples_ts": [ 39.35, 38.9449, 39.2937, 38.5942, 39.7338 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:12Z", "avg_ns": 165444987, "stddev_ns": 2328124, "avg_ts": 48.362137, "stddev_ts": 0.683638, "samples_ns": [ 162010970, 168345291, 165633576, 166448206, 164786896 ],"samples_ts": [ 49.3794, 47.5214, 48.2994, 48.063, 48.5475 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:15Z", "avg_ns": 149215923, "stddev_ns": 750206, "avg_ts": 107.229327, "stddev_ts": 0.538371, "samples_ns": [ 148703693, 150064414, 149976689, 148457498, 148877322 ],"samples_ts": [ 107.597, 106.621, 106.683, 107.775, 107.471 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:18Z", "avg_ns": 218769063, "stddev_ns": 1616418, "avg_ts": 146.279358, "stddev_ts": 1.081321, "samples_ns": [ 217441651, 220527142, 216859251, 218854521, 220162753 ],"samples_ts": [ 147.166, 145.107, 147.561, 146.216, 145.347 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:22Z", "avg_ns": 1050534321, "stddev_ns": 4649655, "avg_ts": 60.922334, "stddev_ts": 0.269669, "samples_ns": [ 1056973472, 1051247902, 1044022608, 1051185685, 1049241942 ],"samples_ts": [ 60.5502, 60.88, 61.3014, 60.8836, 60.9964 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:30Z", "avg_ns": 1500253189, "stddev_ns": 11298994, "avg_ts": 85.322785, "stddev_ts": 0.639441, "samples_ns": [ 1496717946, 1518222895, 1487944057, 1495913668, 1502467383 ],"samples_ts": [ 85.5205, 84.3091, 86.0247, 85.5664, 85.1932 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:32:42Z", "avg_ns": 2785774520, "stddev_ns": 3909967, "avg_ts": 91.895594, "stddev_ts": 0.129027, "samples_ns": [ 2789706703, 2784445294, 2785064035, 2789390464, 2780266104 ],"samples_ts": [ 91.7659, 91.9393, 91.9189, 91.7763, 92.0775 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:33:01Z", "avg_ns": 5698037158, "stddev_ns": 5324728, "avg_ts": 89.855567, "stddev_ts": 0.083959, "samples_ns": [ 5704938553, 5696239023, 5690829630, 5697045797, 5701132790 ],"samples_ts": [ 89.7468, 89.8839, 89.9693, 89.8711, 89.8067 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:33:38Z", "avg_ns": 11638009709, "stddev_ns": 13041489, "avg_ts": 87.987642, "stddev_ts": 0.098573, "samples_ns": [ 11656938842, 11640778811, 11637720458, 11620785400, 11633825037 ],"samples_ts": [ 87.8447, 87.9666, 87.9897, 88.118, 88.0192 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:34:50Z", "avg_ns": 24879976181, "stddev_ns": 17501534, "avg_ts": 82.315224, "stddev_ts": 0.057867, "samples_ns": [ 24863451552, 24879642592, 24869948988, 24877765087, 24909072686 ],"samples_ts": [ 82.3699, 82.3163, 82.3484, 82.3225, 82.219 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T05:37:22Z", "avg_ns": 57015062685, "stddev_ns": 47262489, "avg_ts": 71.840704, "stddev_ts": 0.059584, "samples_ns": [ 56941389561, 56997581792, 57030408697, 57059759247, 57046174132 ],"samples_ts": [ 71.9336, 71.8627, 71.8213, 71.7844, 71.8015 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T05:43:06Z", "avg_ns": 71780626, "stddev_ns": 169550, "avg_ts": 13.931397, "stddev_ts": 0.032799, "samples_ns": [ 71840289, 71699744, 71758756, 72029006, 71575339 ],"samples_ts": [ 13.9198, 13.9471, 13.9356, 13.8833, 13.9713 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T05:43:09Z", "avg_ns": 143661520, "stddev_ns": 727459, "avg_ts": 13.921896, "stddev_ts": 0.070082, "samples_ns": [ 144918228, 143385712, 143360153, 143584958, 143058553 ],"samples_ts": [ 13.8009, 13.9484, 13.9509, 13.929, 13.9803 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T05:43:12Z", "avg_ns": 287987970, "stddev_ns": 509839, "avg_ts": 13.889504, "stddev_ts": 0.024582, "samples_ns": [ 288593777, 287351430, 288402626, 287692694, 287899324 ],"samples_ts": [ 13.8603, 13.9202, 13.8695, 13.9037, 13.8937 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T05:43:16Z", "avg_ns": 576093551, "stddev_ns": 828428, "avg_ts": 13.886656, "stddev_ts": 0.019967, "samples_ns": [ 575624340, 576784783, 575078940, 575896685, 577083007 ],"samples_ts": [ 13.898, 13.87, 13.9111, 13.8914, 13.8628 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T05:43:21Z", "avg_ns": 1151915892, "stddev_ns": 3526984, "avg_ts": 13.890007, "stddev_ts": 0.042403, "samples_ns": [ 1151523210, 1148884804, 1151730201, 1149605938, 1157835310 ],"samples_ts": [ 13.8946, 13.9265, 13.8921, 13.9178, 13.8189 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T05:43:29Z", "avg_ns": 2305274993, "stddev_ns": 2470284, "avg_ts": 13.881220, "stddev_ts": 0.014867, "samples_ns": [ 2308433624, 2307181138, 2304592756, 2302485274, 2303682176 ],"samples_ts": [ 13.8622, 13.8697, 13.8853, 13.898, 13.8908 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T05:43:43Z", "avg_ns": 4599223499, "stddev_ns": 3924920, "avg_ts": 13.915401, "stddev_ts": 0.011863, "samples_ns": [ 4606137165, 4598355431, 4596503422, 4597824682, 4597296795 ],"samples_ts": [ 13.8945, 13.918, 13.9236, 13.9196, 13.9212 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T05:44:09Z", "avg_ns": 9212652820, "stddev_ns": 2475834, "avg_ts": 13.893936, "stddev_ts": 0.003732, "samples_ns": [ 9214028378, 9211831103, 9211327397, 9209885930, 9216191293 ],"samples_ts": [ 13.8919, 13.8952, 13.8959, 13.8981, 13.8886 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T05:44:58Z", "avg_ns": 18425275576, "stddev_ns": 5866870, "avg_ts": 13.893959, "stddev_ts": 0.004425, "samples_ns": [ 18428861985, 18424429684, 18415457192, 18427662541, 18429966478 ],"samples_ts": [ 13.8913, 13.8946, 13.9014, 13.8922, 13.8904 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T05:46:32Z", "avg_ns": 36833002032, "stddev_ns": 6339482, "avg_ts": 13.900578, "stddev_ts": 0.002391, "samples_ns": [ 36838371558, 36838315323, 36833422681, 36832009810, 36822890792 ],"samples_ts": [ 13.8986, 13.8986, 13.9004, 13.901, 13.9044 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T05:49:39Z", "avg_ns": 74256904337, "stddev_ns": 42931292, "avg_ts": 13.789967, "stddev_ts": 0.007972, "samples_ns": [ 74201939234, 74264761685, 74271933220, 74315069113, 74230818433 ],"samples_ts": [ 13.8002, 13.7885, 13.7872, 13.7792, 13.7948 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T05:55:53Z", "avg_ns": 149685866806, "stddev_ns": 46878971, "avg_ts": 13.681988, "stddev_ts": 0.004285, "samples_ns": [ 149677859084, 149620174319, 149715410736, 149743744340, 149672145551 ],"samples_ts": [ 13.6827, 13.688, 13.6793, 13.6767, 13.6832 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T06:08:24Z", "avg_ns": 305280003628, "stddev_ns": 105677302, "avg_ts": 13.417192, "stddev_ts": 0.004645, "samples_ns": [ 305428865430, 305264637104, 305305349801, 305267728533, 305133437272 ],"samples_ts": [ 13.4107, 13.4179, 13.4161, 13.4177, 13.4236 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:33:53Z", "avg_ns": 71437865, "stddev_ns": 170747, "avg_ts": 13.998242, "stddev_ts": 0.033411, "samples_ns": [ 71450077, 71648852, 71358003, 71531841, 71200555 ],"samples_ts": [ 13.9958, 13.957, 14.0138, 13.9798, 14.0448 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:33:55Z", "avg_ns": 83424367, "stddev_ns": 547846, "avg_ts": 23.974635, "stddev_ts": 0.156902, "samples_ns": [ 83683775, 84243633, 82844069, 83153353, 83197006 ],"samples_ts": [ 23.8995, 23.7407, 24.1417, 24.0519, 24.0393 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:33:58Z", "avg_ns": 100945645, "stddev_ns": 1799247, "avg_ts": 39.635238, "stddev_ts": 0.698054, "samples_ns": [ 100499324, 101514242, 103775164, 99648275, 99291221 ],"samples_ts": [ 39.8013, 39.4033, 38.5449, 40.1412, 40.2855 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:01Z", "avg_ns": 204907664, "stddev_ns": 2178181, "avg_ts": 39.045546, "stddev_ts": 0.419860, "samples_ns": [ 205546071, 201163639, 205266643, 206851468, 205710501 ],"samples_ts": [ 38.9207, 39.7686, 38.9737, 38.6751, 38.8896 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:05Z", "avg_ns": 182653977, "stddev_ns": 2727929, "avg_ts": 87.612997, "stddev_ts": 1.311738, "samples_ns": [ 184976479, 178931314, 181721007, 185680819, 181960268 ],"samples_ts": [ 86.4975, 89.4198, 88.0471, 86.1694, 87.9313 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:09Z", "avg_ns": 245518644, "stddev_ns": 2467620, "avg_ts": 130.346909, "stddev_ts": 1.315290, "samples_ns": [ 241965677, 248265592, 244196602, 246288385, 246876968 ],"samples_ts": [ 132.25, 128.894, 131.042, 129.929, 129.619 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:13Z", "avg_ns": 680371476, "stddev_ns": 834485, "avg_ts": 94.066373, "stddev_ts": 0.115208, "samples_ns": [ 680416319, 681625645, 679967732, 680490109, 679357579 ],"samples_ts": [ 94.0601, 93.8932, 94.1221, 94.0499, 94.2066 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:19Z", "avg_ns": 758616663, "stddev_ns": 1784548, "avg_ts": 168.728916, "stddev_ts": 0.397692, "samples_ns": [ 760341331, 755640477, 759397908, 759152474, 758551128 ],"samples_ts": [ 168.345, 169.393, 168.555, 168.609, 168.743 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:26Z", "avg_ns": 1148221168, "stddev_ns": 479325, "avg_ts": 222.953593, "stddev_ts": 0.092600, "samples_ns": [ 1148522976, 1147988244, 1147630759, 1148107831, 1148856034 ],"samples_ts": [ 222.895, 222.999, 223.068, 222.976, 222.83 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:36Z", "avg_ns": 1525874208, "stddev_ns": 5631727, "avg_ts": 335.549009, "stddev_ts": 1.238283, "samples_ns": [ 1519200669, 1521352656, 1527435541, 1533244458, 1528137717 ],"samples_ts": [ 337.019, 336.543, 335.202, 333.932, 335.048 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:34:47Z", "avg_ns": 3158727983, "stddev_ns": 3268827, "avg_ts": 324.181405, "stddev_ts": 0.335373, "samples_ns": [ 3154625013, 3158680756, 3157371331, 3159371771, 3163591044 ],"samples_ts": [ 324.603, 324.186, 324.32, 324.115, 323.683 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:35:09Z", "avg_ns": 6685233989, "stddev_ns": 6684629, "avg_ts": 306.347039, "stddev_ts": 0.306171, "samples_ns": [ 6679877581, 6693443864, 6681307746, 6679999199, 6691541558 ],"samples_ts": [ 306.592, 305.971, 306.527, 306.587, 306.058 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T06:35:51Z", "avg_ns": 14608509183, "stddev_ns": 12013207, "avg_ts": 280.384683, "stddev_ts": 0.230558, "samples_ns": [ 14614423729, 14605724803, 14592285760, 14605423592, 14624688033 ],"samples_ts": [ 280.271, 280.438, 280.696, 280.444, 280.074 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T06:37:22Z", "avg_ns": 71661881, "stddev_ns": 213150, "avg_ts": 13.954519, "stddev_ts": 0.041631, "samples_ns": [ 71783195, 71764579, 71703805, 71772905, 71284923 ],"samples_ts": [ 13.9308, 13.9345, 13.9463, 13.9328, 14.0282 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T06:37:24Z", "avg_ns": 143545794, "stddev_ns": 247602, "avg_ts": 13.932869, "stddev_ts": 0.024042, "samples_ns": [ 143742973, 143773130, 143439770, 143601515, 143171583 ],"samples_ts": [ 13.9137, 13.9108, 13.9431, 13.9274, 13.9693 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T06:37:28Z", "avg_ns": 286335097, "stddev_ns": 675144, "avg_ts": 13.969708, "stddev_ts": 0.032875, "samples_ns": [ 286331625, 286026758, 287449216, 286221246, 285646640 ],"samples_ts": [ 13.9698, 13.9847, 13.9155, 13.9752, 14.0033 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T06:37:32Z", "avg_ns": 572057133, "stddev_ns": 936468, "avg_ts": 13.984647, "stddev_ts": 0.022878, "samples_ns": [ 571499890, 573133648, 571135351, 573002249, 571514528 ],"samples_ts": [ 13.9983, 13.9583, 14.0072, 13.9616, 13.9979 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T06:37:37Z", "avg_ns": 1144624488, "stddev_ns": 826867, "avg_ts": 13.978389, "stddev_ts": 0.010090, "samples_ns": [ 1144524261, 1143990251, 1144958682, 1145856238, 1143793009 ],"samples_ts": [ 13.9796, 13.9861, 13.9743, 13.9634, 13.9885 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T06:37:45Z", "avg_ns": 2286792520, "stddev_ns": 1429280, "avg_ts": 13.993403, "stddev_ts": 0.008736, "samples_ns": [ 2287391680, 2288725139, 2287031629, 2285692558, 2285121598 ],"samples_ts": [ 13.9897, 13.9816, 13.9919, 14.0001, 14.0036 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T06:37:59Z", "avg_ns": 4582492528, "stddev_ns": 3385619, "avg_ts": 13.966205, "stddev_ts": 0.010317, "samples_ns": [ 4586766831, 4581208003, 4583984260, 4577640711, 4582862838 ],"samples_ts": [ 13.9532, 13.9701, 13.9617, 13.981, 13.9651 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T06:38:25Z", "avg_ns": 9192555290, "stddev_ns": 2979366, "avg_ts": 13.924312, "stddev_ts": 0.004507, "samples_ns": [ 9197705605, 9190242247, 9190880748, 9192170140, 9191777714 ],"samples_ts": [ 13.9165, 13.9278, 13.9268, 13.9249, 13.9255 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T06:39:13Z", "avg_ns": 18485935029, "stddev_ns": 4090380, "avg_ts": 13.848367, "stddev_ts": 0.003063, "samples_ns": [ 18485294005, 18486213444, 18482750452, 18482710290, 18492706955 ],"samples_ts": [ 13.8488, 13.8482, 13.8508, 13.8508, 13.8433 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T06:40:48Z", "avg_ns": 37429958950, "stddev_ns": 12985803, "avg_ts": 13.678884, "stddev_ts": 0.004747, "samples_ns": [ 37433049938, 37439512682, 37437518599, 37432351072, 37407362462 ],"samples_ts": [ 13.6778, 13.6754, 13.6761, 13.678, 13.6871 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T06:43:57Z", "avg_ns": 76415516490, "stddev_ns": 8331268, "avg_ts": 13.400420, "stddev_ts": 0.001460, "samples_ns": [ 76402759546, 76415375069, 76417267468, 76426058925, 76416121444 ],"samples_ts": [ 13.4027, 13.4004, 13.4001, 13.3986, 13.4003 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T06:50:22Z", "avg_ns": 159975742855, "stddev_ns": 23033477, "avg_ts": 12.801941, "stddev_ts": 0.001843, "samples_ns": [ 160000383694, 159950884152, 159952549676, 159980975496, 159993921261 ],"samples_ts": [ 12.8, 12.8039, 12.8038, 12.8015, 12.8005 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T07:03:45Z", "avg_ns": 345799599340, "stddev_ns": 23136747, "avg_ts": 11.845011, "stddev_ts": 0.000792, "samples_ns": [ 345801908704, 345784036651, 345837496752, 345796027584, 345778527010 ],"samples_ts": [ 11.8449, 11.8455, 11.8437, 11.8451, 11.8457 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:32:36Z", "avg_ns": 71853000, "stddev_ns": 112060, "avg_ts": 13.917330, "stddev_ts": 0.021682, "samples_ns": [ 71811125, 71812568, 71877099, 72031381, 71732827 ],"samples_ts": [ 13.9254, 13.9251, 13.9126, 13.8828, 13.9406 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:32:39Z", "avg_ns": 84047128, "stddev_ns": 458971, "avg_ts": 23.796739, "stddev_ts": 0.129687, "samples_ns": [ 83860542, 83483800, 84192690, 84727670, 83970940 ],"samples_ts": [ 23.8491, 23.9567, 23.755, 23.605, 23.8178 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:32:42Z", "avg_ns": 103018830, "stddev_ns": 889035, "avg_ts": 38.830171, "stddev_ts": 0.335780, "samples_ns": [ 104117446, 103511812, 102980658, 102743571, 101740666 ],"samples_ts": [ 38.4182, 38.6429, 38.8422, 38.9319, 39.3156 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:32:45Z", "avg_ns": 165393057, "stddev_ns": 2364288, "avg_ts": 48.377440, "stddev_ts": 0.683466, "samples_ns": [ 164942073, 169278496, 164023047, 163125752, 165595919 ],"samples_ts": [ 48.5019, 47.2594, 48.7736, 49.0419, 48.3104 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:32:48Z", "avg_ns": 148747261, "stddev_ns": 1579468, "avg_ts": 107.574768, "stddev_ts": 1.149351, "samples_ns": [ 149356234, 150153761, 147923257, 149917856, 146385201 ],"samples_ts": [ 107.126, 106.557, 108.164, 106.725, 109.301 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:32:51Z", "avg_ns": 219326048, "stddev_ns": 1423663, "avg_ts": 145.906389, "stddev_ts": 0.941180, "samples_ns": [ 218483979, 221720685, 218055009, 219124390, 219246180 ],"samples_ts": [ 146.464, 144.326, 146.752, 146.036, 145.955 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:32:55Z", "avg_ns": 668672270, "stddev_ns": 872077, "avg_ts": 95.712189, "stddev_ts": 0.124679, "samples_ns": [ 667769222, 668679301, 670084186, 668192272, 668636370 ],"samples_ts": [ 95.8415, 95.7111, 95.5104, 95.7808, 95.7172 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:33:01Z", "avg_ns": 766933643, "stddev_ns": 1233576, "avg_ts": 166.898748, "stddev_ts": 0.268241, "samples_ns": [ 765521322, 766657690, 768810087, 767328076, 766351040 ],"samples_ts": [ 167.206, 166.958, 166.491, 166.813, 167.025 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:33:08Z", "avg_ns": 1207482098, "stddev_ns": 4021886, "avg_ts": 212.013308, "stddev_ts": 0.706784, "samples_ns": [ 1205234480, 1201930737, 1211530065, 1211001096, 1207714116 ],"samples_ts": [ 212.407, 212.991, 211.303, 211.395, 211.971 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:33:18Z", "avg_ns": 1766257990, "stddev_ns": 8037276, "avg_ts": 289.883182, "stddev_ts": 1.319930, "samples_ns": [ 1772909670, 1774775215, 1756731863, 1759257777, 1767615428 ],"samples_ts": [ 288.791, 288.487, 291.45, 291.032, 289.656 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:33:31Z", "avg_ns": 3932860711, "stddev_ns": 5230130, "avg_ts": 260.370637, "stddev_ts": 0.346292, "samples_ns": [ 3926367384, 3928659668, 3934543417, 3935612589, 3939120499 ],"samples_ts": [ 260.801, 260.649, 260.259, 260.188, 259.957 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:33:57Z", "avg_ns": 9495786186, "stddev_ns": 8779735, "avg_ts": 215.674759, "stddev_ts": 0.199368, "samples_ns": [ 9491176730, 9485241356, 9502656322, 9493060761, 9506795764 ],"samples_ts": [ 215.779, 215.914, 215.519, 215.737, 215.425 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T07:34:56Z", "avg_ns": 25851842781, "stddev_ns": 23189367, "avg_ts": 158.441418, "stddev_ts": 0.142191, "samples_ns": [ 25816221654, 25846818785, 25868846799, 25851658282, 25875668386 ],"samples_ts": [ 158.66, 158.472, 158.337, 158.442, 158.295 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T07:37:34Z", "avg_ns": 71834273, "stddev_ns": 113967, "avg_ts": 13.920960, "stddev_ts": 0.022067, "samples_ns": [ 71758568, 71998452, 71741495, 71909403, 71763447 ],"samples_ts": [ 13.9356, 13.8892, 13.9389, 13.9064, 13.9347 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T07:37:36Z", "avg_ns": 144103495, "stddev_ns": 321559, "avg_ts": 13.878969, "stddev_ts": 0.030918, "samples_ns": [ 144223731, 143850546, 144172645, 144539758, 143730799 ],"samples_ts": [ 13.8673, 13.9033, 13.8723, 13.837, 13.9149 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T07:37:40Z", "avg_ns": 287385550, "stddev_ns": 330512, "avg_ts": 13.918599, "stddev_ts": 0.015996, "samples_ns": [ 287394783, 287248127, 287496336, 287844243, 286944262 ],"samples_ts": [ 13.9181, 13.9252, 13.9132, 13.8964, 13.94 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T07:37:44Z", "avg_ns": 575125650, "stddev_ns": 765722, "avg_ts": 13.910024, "stddev_ts": 0.018521, "samples_ns": [ 575953066, 575576855, 574367069, 575476084, 574255177 ],"samples_ts": [ 13.89, 13.8991, 13.9284, 13.9015, 13.9311 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T07:37:49Z", "avg_ns": 1150426996, "stddev_ns": 522684, "avg_ts": 13.907882, "stddev_ts": 0.006294, "samples_ns": [ 1150986504, 1149596668, 1150325786, 1150584284, 1150641742 ],"samples_ts": [ 13.9011, 13.9179, 13.9091, 13.906, 13.9053 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T07:37:58Z", "avg_ns": 2296173829, "stddev_ns": 1330704, "avg_ts": 13.936231, "stddev_ts": 0.008064, "samples_ns": [ 2294973352, 2298452086, 2295691791, 2295757836, 2295994083 ],"samples_ts": [ 13.9435, 13.9224, 13.9392, 13.9388, 13.9373 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T07:38:11Z", "avg_ns": 4601758419, "stddev_ns": 2865075, "avg_ts": 13.907731, "stddev_ts": 0.008651, "samples_ns": [ 4606822817, 4600451741, 4600998064, 4600706756, 4599812718 ],"samples_ts": [ 13.8924, 13.9117, 13.91, 13.9109, 13.9136 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T07:38:37Z", "avg_ns": 9186944998, "stddev_ns": 1469988, "avg_ts": 13.932815, "stddev_ts": 0.002227, "samples_ns": [ 9186681766, 9185148323, 9186240212, 9187616970, 9189037720 ],"samples_ts": [ 13.9332, 13.9355, 13.9339, 13.9318, 13.9296 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T07:39:25Z", "avg_ns": 18388921503, "stddev_ns": 11161030, "avg_ts": 13.921430, "stddev_ts": 0.008446, "samples_ns": [ 18404197287, 18379361621, 18383740346, 18380098462, 18397209803 ],"samples_ts": [ 13.9099, 13.9287, 13.9253, 13.9281, 13.9152 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T07:41:00Z", "avg_ns": 36828839632, "stddev_ns": 13146676, "avg_ts": 13.902150, "stddev_ts": 0.004962, "samples_ns": [ 36817270081, 36847566069, 36833372641, 36815315768, 36830673601 ],"samples_ts": [ 13.9065, 13.8951, 13.9004, 13.9073, 13.9015 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T07:44:06Z", "avg_ns": 74118023629, "stddev_ns": 10140364, "avg_ts": 13.815803, "stddev_ts": 0.001890, "samples_ns": [ 74113494730, 74104185772, 74121211081, 74131693793, 74119532769 ],"samples_ts": [ 13.8166, 13.8184, 13.8152, 13.8133, 13.8155 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T07:50:19Z", "avg_ns": 149572365641, "stddev_ns": 18033753, "avg_ts": 13.692369, "stddev_ts": 0.001650, "samples_ns": [ 149554657180, 149573330066, 149579760394, 149598096897, 149555983672 ],"samples_ts": [ 13.694, 13.6923, 13.6917, 13.69, 13.6939 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T08:02:50Z", "avg_ns": 304740386566, "stddev_ns": 41613600, "avg_ts": 13.440949, "stddev_ts": 0.001835, "samples_ns": [ 304773099362, 304794384916, 304721556982, 304718288154, 304694603419 ],"samples_ts": [ 13.4395, 13.4386, 13.4418, 13.4419, 13.443 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:17Z", "avg_ns": 68264602, "stddev_ns": 160534, "avg_ts": 14.648945, "stddev_ts": 0.034383, "samples_ns": [ 68283726, 68232469, 68527056, 68168979, 68110780 ],"samples_ts": [ 14.6448, 14.6558, 14.5928, 14.6694, 14.682 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:20Z", "avg_ns": 71023377, "stddev_ns": 321971, "avg_ts": 28.160204, "stddev_ts": 0.127415, "samples_ns": [ 71274057, 70804359, 71449208, 70888409, 70700854 ],"samples_ts": [ 28.0607, 28.2468, 27.9919, 28.2134, 28.2882 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:24Z", "avg_ns": 84968477, "stddev_ns": 614399, "avg_ts": 47.078240, "stddev_ts": 0.338590, "samples_ns": [ 85958947, 84948347, 84571946, 85002750, 84360397 ],"samples_ts": [ 46.5338, 47.0874, 47.297, 47.0573, 47.4156 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:27Z", "avg_ns": 160656207, "stddev_ns": 1322817, "avg_ts": 49.798461, "stddev_ts": 0.408034, "samples_ns": [ 160390441, 162763685, 160669408, 159109570, 160347931 ],"samples_ts": [ 49.8783, 49.151, 49.7917, 50.2798, 49.8915 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:32Z", "avg_ns": 242258721, "stddev_ns": 2512244, "avg_ts": 66.050724, "stddev_ts": 0.678645, "samples_ns": [ 246387258, 242859022, 241123122, 240245774, 240678432 ],"samples_ts": [ 64.9384, 65.8818, 66.3561, 66.5985, 66.4787 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:36Z", "avg_ns": 264759765, "stddev_ns": 4043361, "avg_ts": 120.886659, "stddev_ts": 1.831391, "samples_ns": [ 270894872, 266435504, 260416831, 262837305, 263214317 ],"samples_ts": [ 118.127, 120.104, 122.88, 121.748, 121.574 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:40Z", "avg_ns": 392454116, "stddev_ns": 1436279, "avg_ts": 163.078133, "stddev_ts": 0.595986, "samples_ns": [ 394210081, 391515158, 391164365, 393810706, 391570272 ],"samples_ts": [ 162.35, 163.467, 163.614, 162.515, 163.444 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:45Z", "avg_ns": 623866176, "stddev_ns": 527846, "avg_ts": 205.172323, "stddev_ts": 0.173258, "samples_ns": [ 623935263, 623602685, 624430700, 624250379, 623111857 ],"samples_ts": [ 205.149, 205.259, 204.987, 205.046, 205.421 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:28:52Z", "avg_ns": 1249600587, "stddev_ns": 6673935, "avg_ts": 204.870105, "stddev_ts": 1.087001, "samples_ns": [ 1244737114, 1247532126, 1247562764, 1246810413, 1261360518 ],"samples_ts": [ 205.666, 205.205, 205.2, 205.324, 202.955 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:29:02Z", "avg_ns": 2510579621, "stddev_ns": 14684255, "avg_ts": 203.942578, "stddev_ts": 1.198709, "samples_ns": [ 2486934579, 2505635146, 2521249091, 2518030198, 2521049094 ],"samples_ts": [ 205.876, 204.339, 203.074, 203.334, 203.09 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:29:20Z", "avg_ns": 5235983536, "stddev_ns": 9338221, "avg_ts": 195.570249, "stddev_ts": 0.348608, "samples_ns": [ 5224168050, 5231893337, 5237581074, 5249753084, 5236522138 ],"samples_ts": [ 196.012, 195.723, 195.51, 195.057, 195.55 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:29:54Z", "avg_ns": 10706428635, "stddev_ns": 4654545, "avg_ts": 191.286972, "stddev_ts": 0.083168, "samples_ns": [ 10707742913, 10710584681, 10710800500, 10701271327, 10701743754 ],"samples_ts": [ 191.263, 191.213, 191.209, 191.379, 191.371 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T08:31:01Z", "avg_ns": 21893674726, "stddev_ns": 15732578, "avg_ts": 187.086076, "stddev_ts": 0.134427, "samples_ns": [ 21890624319, 21872040739, 21891233601, 21898908791, 21915566183 ],"samples_ts": [ 187.112, 187.271, 187.107, 187.041, 186.899 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T08:33:15Z", "avg_ns": 68231801, "stddev_ns": 214917, "avg_ts": 14.656039, "stddev_ts": 0.046234, "samples_ns": [ 68372803, 68352896, 68413651, 67913746, 68105910 ],"samples_ts": [ 14.6257, 14.63, 14.617, 14.7246, 14.683 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T08:33:18Z", "avg_ns": 136686012, "stddev_ns": 584349, "avg_ts": 14.632288, "stddev_ts": 0.062235, "samples_ns": [ 136367111, 136359337, 136323630, 136681275, 137698709 ],"samples_ts": [ 14.6663, 14.6671, 14.671, 14.6326, 14.5245 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T08:33:21Z", "avg_ns": 273791641, "stddev_ns": 352289, "avg_ts": 14.609669, "stddev_ts": 0.018768, "samples_ns": [ 273743861, 274167402, 273353684, 273569632, 274123629 ],"samples_ts": [ 14.6122, 14.5896, 14.6331, 14.6215, 14.592 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T08:33:25Z", "avg_ns": 547136787, "stddev_ns": 771479, "avg_ts": 14.621595, "stddev_ts": 0.020619, "samples_ns": [ 546695816, 546133573, 547080352, 547727856, 548046338 ],"samples_ts": [ 14.6334, 14.6484, 14.6231, 14.6058, 14.5973 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T08:33:30Z", "avg_ns": 1095667784, "stddev_ns": 1770831, "avg_ts": 14.602997, "stddev_ts": 0.023572, "samples_ns": [ 1093930089, 1095645521, 1094282695, 1096089139, 1098391480 ],"samples_ts": [ 14.6262, 14.6033, 14.6215, 14.5974, 14.5668 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T08:33:38Z", "avg_ns": 2192633653, "stddev_ns": 2486229, "avg_ts": 14.594336, "stddev_ts": 0.016548, "samples_ns": [ 2189871869, 2190282084, 2192963750, 2194952830, 2195097734 ],"samples_ts": [ 14.6127, 14.61, 14.5921, 14.5789, 14.5779 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T08:33:52Z", "avg_ns": 4392948029, "stddev_ns": 5977926, "avg_ts": 14.568826, "stddev_ts": 0.019821, "samples_ns": [ 4384823065, 4392661978, 4393730967, 4391908142, 4401615995 ],"samples_ts": [ 14.5958, 14.5698, 14.5662, 14.5723, 14.5401 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T08:34:17Z", "avg_ns": 8788510801, "stddev_ns": 4056061, "avg_ts": 14.564472, "stddev_ts": 0.006721, "samples_ns": [ 8781842049, 8789806615, 8787771860, 8791991742, 8791141743 ],"samples_ts": [ 14.5755, 14.5623, 14.5657, 14.5587, 14.5601 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T08:35:03Z", "avg_ns": 17625018244, "stddev_ns": 6125046, "avg_ts": 14.524809, "stddev_ts": 0.005047, "samples_ns": [ 17623684061, 17629431021, 17632452795, 17616741636, 17622781708 ],"samples_ts": [ 14.5259, 14.5212, 14.5187, 14.5316, 14.5267 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T08:36:34Z", "avg_ns": 35398173146, "stddev_ns": 12315984, "avg_ts": 14.464025, "stddev_ts": 0.005032, "samples_ns": [ 35413683319, 35400789918, 35391799725, 35381127540, 35403465230 ],"samples_ts": [ 14.4577, 14.463, 14.4666, 14.471, 14.4619 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T08:39:34Z", "avg_ns": 71708695612, "stddev_ns": 9949387, "avg_ts": 14.279998, "stddev_ts": 0.001981, "samples_ns": [ 71724580615, 71708969384, 71709131069, 71702062177, 71698734816 ],"samples_ts": [ 14.2768, 14.2799, 14.2799, 14.2813, 14.282 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T08:45:35Z", "avg_ns": 148217275078, "stddev_ns": 18304075, "avg_ts": 13.817553, "stddev_ts": 0.001706, "samples_ns": [ 148241813675, 148214111724, 148229720481, 148200277005, 148200452509 ],"samples_ts": [ 13.8153, 13.8178, 13.8164, 13.8191, 13.8191 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T08:57:59Z", "avg_ns": 310964553372, "stddev_ns": 17073416, "avg_ts": 13.171919, "stddev_ts": 0.000723, "samples_ns": [ 310974527766, 310964260404, 310982465185, 310964264258, 310937249247 ],"samples_ts": [ 13.1715, 13.1719, 13.1712, 13.1719, 13.1731 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:23:57Z", "avg_ns": 69234019, "stddev_ns": 139628, "avg_ts": 14.443813, "stddev_ts": 0.029106, "samples_ns": [ 69186844, 69428921, 69100531, 69127271, 69326528 ],"samples_ts": [ 14.4536, 14.4032, 14.4717, 14.4661, 14.4245 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:00Z", "avg_ns": 73667168, "stddev_ns": 209287, "avg_ts": 27.149311, "stddev_ts": 0.076989, "samples_ns": [ 73928853, 73684161, 73477751, 73804178, 73440901 ],"samples_ts": [ 27.053, 27.1429, 27.2191, 27.0987, 27.2328 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:03Z", "avg_ns": 87461079, "stddev_ns": 326978, "avg_ts": 45.735139, "stddev_ts": 0.170689, "samples_ns": [ 87319765, 87711404, 87107033, 87891114, 87276082 ],"samples_ts": [ 45.8086, 45.6041, 45.9205, 45.5109, 45.8316 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:06Z", "avg_ns": 162751738, "stddev_ns": 2394360, "avg_ts": 49.163091, "stddev_ts": 0.719817, "samples_ns": [ 166383621, 162778460, 162781845, 162118803, 159695965 ],"samples_ts": [ 48.0817, 49.1466, 49.1455, 49.3465, 50.0952 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:09Z", "avg_ns": 245923721, "stddev_ns": 1581822, "avg_ts": 65.062973, "stddev_ts": 0.417606, "samples_ns": [ 247548838, 247730751, 244978312, 244440465, 244920242 ],"samples_ts": [ 64.6337, 64.5862, 65.3119, 65.4556, 65.3274 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:14Z", "avg_ns": 268350184, "stddev_ns": 3181710, "avg_ts": 119.260504, "stddev_ts": 1.405852, "samples_ns": [ 273170419, 265141119, 268313142, 265872040, 269254201 ],"samples_ts": [ 117.143, 120.69, 119.264, 120.359, 118.847 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:18Z", "avg_ns": 395895410, "stddev_ns": 1549940, "avg_ts": 161.660837, "stddev_ts": 0.631905, "samples_ns": [ 398219664, 394012194, 395395878, 395473115, 396376201 ],"samples_ts": [ 160.715, 162.432, 161.863, 161.831, 161.463 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:23Z", "avg_ns": 635152654, "stddev_ns": 841279, "avg_ts": 201.526638, "stddev_ts": 0.266320, "samples_ns": [ 634392572, 634928805, 634810723, 635040277, 636590897 ],"samples_ts": [ 201.768, 201.597, 201.635, 201.562, 201.071 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:29Z", "avg_ns": 1258353587, "stddev_ns": 9897487, "avg_ts": 203.450403, "stddev_ts": 1.584305, "samples_ns": [ 1252062003, 1254487488, 1253521193, 1255808656, 1275888597 ],"samples_ts": [ 204.463, 204.067, 204.225, 203.853, 200.644 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:40Z", "avg_ns": 2518982782, "stddev_ns": 13081953, "avg_ts": 203.261058, "stddev_ts": 1.061092, "samples_ns": [ 2496949462, 2517756772, 2523849708, 2529719674, 2526638295 ],"samples_ts": [ 205.05, 203.356, 202.865, 202.394, 202.641 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:24:57Z", "avg_ns": 5108511687, "stddev_ns": 8712385, "avg_ts": 200.450238, "stddev_ts": 0.341687, "samples_ns": [ 5097435849, 5111324990, 5106428234, 5106097107, 5121272258 ],"samples_ts": [ 200.885, 200.339, 200.532, 200.545, 199.95 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:25:31Z", "avg_ns": 10507656299, "stddev_ns": 11118968, "avg_ts": 194.905674, "stddev_ts": 0.206016, "samples_ns": [ 10509536313, 10500254574, 10526343895, 10501438940, 10500707775 ],"samples_ts": [ 194.871, 195.043, 194.559, 195.021, 195.034 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T09:26:36Z", "avg_ns": 22179961388, "stddev_ns": 14004204, "avg_ts": 184.671255, "stddev_ts": 0.116566, "samples_ns": [ 22174742043, 22196984268, 22192680791, 22169249625, 22166150217 ],"samples_ts": [ 184.715, 184.53, 184.565, 184.76, 184.786 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T09:28:52Z", "avg_ns": 69082819, "stddev_ns": 134483, "avg_ts": 14.475423, "stddev_ts": 0.028126, "samples_ns": [ 69110381, 68923238, 69054155, 69036181, 69290141 ],"samples_ts": [ 14.4696, 14.5089, 14.4814, 14.4852, 14.4321 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T09:28:54Z", "avg_ns": 138585940, "stddev_ns": 338409, "avg_ts": 14.431547, "stddev_ts": 0.035165, "samples_ns": [ 138377509, 138552890, 138231382, 138649813, 139118108 ],"samples_ts": [ 14.4532, 14.4349, 14.4685, 14.4248, 14.3763 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T09:28:58Z", "avg_ns": 277369282, "stddev_ns": 222153, "avg_ts": 14.421215, "stddev_ts": 0.011539, "samples_ns": [ 277324574, 277476340, 277027132, 277625763, 277392602 ],"samples_ts": [ 14.4235, 14.4156, 14.439, 14.4079, 14.42 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T09:29:02Z", "avg_ns": 554844655, "stddev_ns": 1166700, "avg_ts": 14.418501, "stddev_ts": 0.030288, "samples_ns": [ 554122423, 554088279, 556087365, 556140646, 553784565 ],"samples_ts": [ 14.4372, 14.4381, 14.3862, 14.3849, 14.4461 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T09:29:07Z", "avg_ns": 1111224387, "stddev_ns": 1054392, "avg_ts": 14.398542, "stddev_ts": 0.013667, "samples_ns": [ 1109593968, 1110792933, 1111601321, 1111927678, 1112206036 ],"samples_ts": [ 14.4197, 14.4041, 14.3936, 14.3894, 14.3858 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T09:29:16Z", "avg_ns": 2224124290, "stddev_ns": 2468152, "avg_ts": 14.387699, "stddev_ts": 0.015974, "samples_ns": [ 2220209193, 2224113502, 2225981614, 2226469398, 2223847746 ],"samples_ts": [ 14.4131, 14.3878, 14.3757, 14.3725, 14.3895 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T09:29:29Z", "avg_ns": 4449246928, "stddev_ns": 3468587, "avg_ts": 14.384464, "stddev_ts": 0.011217, "samples_ns": [ 4444104228, 4449490946, 4448057745, 4453205270, 4451376451 ],"samples_ts": [ 14.4011, 14.3837, 14.3883, 14.3717, 14.3776 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T09:29:54Z", "avg_ns": 8906920297, "stddev_ns": 2920866, "avg_ts": 14.370849, "stddev_ts": 0.004710, "samples_ns": [ 8909557832, 8903485388, 8909792104, 8907454086, 8904312077 ],"samples_ts": [ 14.3666, 14.3764, 14.3662, 14.37, 14.3751 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T09:30:42Z", "avg_ns": 17808346562, "stddev_ns": 5957351, "avg_ts": 14.375283, "stddev_ts": 0.004807, "samples_ns": [ 17809563118, 17815818657, 17810067692, 17799442926, 17806840421 ],"samples_ts": [ 14.3743, 14.3693, 14.3739, 14.3825, 14.3765 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T09:32:14Z", "avg_ns": 35685403927, "stddev_ns": 7024369, "avg_ts": 14.347603, "stddev_ts": 0.002823, "samples_ns": [ 35679991420, 35694805181, 35677892678, 35684262484, 35690067875 ],"samples_ts": [ 14.3498, 14.3438, 14.3506, 14.3481, 14.3457 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T09:35:15Z", "avg_ns": 71819540976, "stddev_ns": 8819896, "avg_ts": 14.257958, "stddev_ts": 0.001750, "samples_ns": [ 71827937568, 71810211667, 71823883618, 71809819773, 71825852257 ],"samples_ts": [ 14.2563, 14.2598, 14.2571, 14.2599, 14.2567 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T09:41:16Z", "avg_ns": 145310754236, "stddev_ns": 10553085, "avg_ts": 14.093933, "stddev_ts": 0.001022, "samples_ns": [ 145301511176, 145316254557, 145300804521, 145309357839, 145325843091 ],"samples_ts": [ 14.0948, 14.0934, 14.0949, 14.0941, 14.0925 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "Radeon 8060S Graphics", "backends": "Vulkan", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T09:53:26Z", "avg_ns": 296930903942, "stddev_ns": 20889368, "avg_ts": 13.794455, "stddev_ts": 0.000970, "samples_ns": [ 296965419443, 296934643364, 296922446056, 296912491714, 296919519133 ],"samples_ts": [ 13.7929, 13.7943, 13.7948, 13.7953, 13.795 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:13Z", "avg_ns": 71733973, "stddev_ns": 370195, "avg_ts": 13.940692, "stddev_ts": 0.071755, "samples_ns": [ 71692320, 71685327, 72316029, 71693493, 71282696 ],"samples_ts": [ 13.9485, 13.9499, 13.8282, 13.9483, 14.0287 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:16Z", "avg_ns": 83568301, "stddev_ns": 387266, "avg_ts": 23.932930, "stddev_ts": 0.110754, "samples_ns": [ 83174527, 84099886, 83748432, 83210877, 83607786 ],"samples_ts": [ 24.0458, 23.7812, 23.881, 24.0353, 23.9212 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:19Z", "avg_ns": 99069821, "stddev_ns": 520028, "avg_ts": 40.376449, "stddev_ts": 0.210506, "samples_ns": [ 98713190, 99986766, 98899752, 98938275, 98811125 ],"samples_ts": [ 40.5214, 40.0053, 40.445, 40.4292, 40.4813 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:22Z", "avg_ns": 160397445, "stddev_ns": 3267157, "avg_ts": 49.892713, "stddev_ts": 1.019232, "samples_ns": [ 156076344, 164221465, 160386638, 158498120, 162804658 ],"samples_ts": [ 51.257, 48.7147, 49.8795, 50.4738, 49.1386 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:25Z", "avg_ns": 141384111, "stddev_ns": 1263908, "avg_ts": 113.174124, "stddev_ts": 1.011740, "samples_ns": [ 139985068, 141533624, 142252553, 142913090, 140236222 ],"samples_ts": [ 114.298, 113.047, 112.476, 111.956, 114.093 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:28Z", "avg_ns": 202276881, "stddev_ns": 1030973, "avg_ts": 158.202289, "stddev_ts": 0.806902, "samples_ns": [ 201749749, 203152480, 200901676, 203418262, 202162238 ],"samples_ts": [ 158.612, 157.517, 159.282, 157.311, 158.289 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:31Z", "avg_ns": 1024120986, "stddev_ns": 4781660, "avg_ts": 62.493701, "stddev_ts": 0.290434, "samples_ns": [ 1032208997, 1022619136, 1021664012, 1019909095, 1024203691 ],"samples_ts": [ 62.0029, 62.5844, 62.6429, 62.7507, 62.4876 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:40Z", "avg_ns": 1473751458, "stddev_ns": 7596045, "avg_ts": 86.855019, "stddev_ts": 0.446049, "samples_ns": [ 1473902319, 1486046998, 1465304473, 1471408559, 1472094945 ],"samples_ts": [ 86.8443, 86.1346, 87.3539, 86.9915, 86.9509 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:18:51Z", "avg_ns": 2696529322, "stddev_ns": 3647847, "avg_ts": 94.936989, "stddev_ts": 0.128421, "samples_ns": [ 2697083928, 2701085451, 2692134528, 2693663368, 2698679337 ],"samples_ts": [ 94.9173, 94.7767, 95.0918, 95.0379, 94.8612 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:19:10Z", "avg_ns": 5382510765, "stddev_ns": 9354825, "avg_ts": 95.123124, "stddev_ts": 0.165452, "samples_ns": [ 5387140455, 5378330642, 5392983385, 5385470182, 5368629162 ],"samples_ts": [ 95.0411, 95.1968, 94.9382, 95.0706, 95.3689 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:19:45Z", "avg_ns": 10793868301, "stddev_ns": 15428584, "avg_ts": 94.868832, "stddev_ts": 0.135628, "samples_ns": [ 10812488673, 10774375148, 10782025479, 10798755608, 10801696599 ],"samples_ts": [ 94.7053, 95.0403, 94.9729, 94.8257, 94.7999 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:20:52Z", "avg_ns": 21890365890, "stddev_ns": 136663514, "avg_ts": 93.560032, "stddev_ts": 0.579373, "samples_ns": [ 21822896273, 21832111880, 21812991139, 21850227722, 22133602437 ],"samples_ts": [ 93.8464, 93.8068, 93.889, 93.729, 92.529 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T10:23:06Z", "avg_ns": 44742642113, "stddev_ns": 218097561, "avg_ts": 91.547521, "stddev_ts": 0.446996, "samples_ns": [ 44931842545, 44908484413, 44483280185, 44528790663, 44860812763 ],"samples_ts": [ 91.1603, 91.2077, 92.0795, 91.9854, 91.3046 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T10:27:37Z", "avg_ns": 71757365, "stddev_ns": 197911, "avg_ts": 13.935936, "stddev_ts": 0.038403, "samples_ns": [ 71836276, 72018441, 71500191, 71637111, 71794808 ],"samples_ts": [ 13.9205, 13.8853, 13.986, 13.9592, 13.9286 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T10:27:40Z", "avg_ns": 143348310, "stddev_ns": 132495, "avg_ts": 13.952040, "stddev_ts": 0.012844, "samples_ns": [ 143480570, 143365663, 143468908, 143193177, 143233234 ],"samples_ts": [ 13.9392, 13.9503, 13.9403, 13.9671, 13.9632 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T10:27:43Z", "avg_ns": 286462587, "stddev_ns": 238428, "avg_ts": 13.963437, "stddev_ts": 0.011607, "samples_ns": [ 286509278, 286238576, 286208809, 286585581, 286770692 ],"samples_ts": [ 13.9612, 13.9744, 13.9758, 13.9574, 13.9484 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T10:27:47Z", "avg_ns": 572439105, "stddev_ns": 152243, "avg_ts": 13.975286, "stddev_ts": 0.003623, "samples_ns": [ 572375139, 572699442, 572383985, 572408803, 572328160 ],"samples_ts": [ 13.9768, 13.9689, 13.9766, 13.976, 13.978 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T10:27:52Z", "avg_ns": 1146834212, "stddev_ns": 754266, "avg_ts": 13.951455, "stddev_ts": 0.009163, "samples_ns": [ 1146282404, 1146621314, 1146147058, 1148004628, 1147115658 ],"samples_ts": [ 13.9582, 13.954, 13.9598, 13.9372, 13.948 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T10:28:00Z", "avg_ns": 2290022185, "stddev_ns": 1226086, "avg_ts": 13.973667, "stddev_ts": 0.007469, "samples_ns": [ 2289865737, 2292095642, 2289791658, 2288862352, 2289495539 ],"samples_ts": [ 13.9746, 13.961, 13.9751, 13.9807, 13.9769 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T10:28:14Z", "avg_ns": 4586302602, "stddev_ns": 1026549, "avg_ts": 13.954597, "stddev_ts": 0.003120, "samples_ns": [ 4587386865, 4586335339, 4585269977, 4585270599, 4587250231 ],"samples_ts": [ 13.9513, 13.9545, 13.9577, 13.9577, 13.9517 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T10:28:39Z", "avg_ns": 9201018775, "stddev_ns": 1365425, "avg_ts": 13.911503, "stddev_ts": 0.002065, "samples_ns": [ 9201641123, 9200834012, 9198734088, 9201707370, 9202177282 ],"samples_ts": [ 13.9106, 13.9118, 13.915, 13.9105, 13.9098 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T10:29:28Z", "avg_ns": 18524595996, "stddev_ns": 3373956, "avg_ts": 13.819465, "stddev_ts": 0.002515, "samples_ns": [ 18520635982, 18524742906, 18522869450, 18529756648, 18524974996 ],"samples_ts": [ 13.8224, 13.8194, 13.8208, 13.8156, 13.8192 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T10:31:03Z", "avg_ns": 37494711490, "stddev_ns": 7325329, "avg_ts": 13.655260, "stddev_ts": 0.002666, "samples_ns": [ 37506186770, 37490422468, 37486965761, 37493557478, 37496424977 ],"samples_ts": [ 13.6511, 13.6568, 13.6581, 13.6557, 13.6546 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T10:34:13Z", "avg_ns": 76640783689, "stddev_ns": 4829208, "avg_ts": 13.361033, "stddev_ts": 0.000841, "samples_ns": [ 76644098336, 76637632962, 76647121049, 76639869963, 76635196136 ],"samples_ts": [ 13.3605, 13.3616, 13.3599, 13.3612, 13.362 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T10:40:39Z", "avg_ns": 160249975879, "stddev_ns": 10792456, "avg_ts": 12.780033, "stddev_ts": 0.000861, "samples_ns": [ 160240492121, 160256872353, 160262767999, 160252380050, 160237366872 ],"samples_ts": [ 12.7808, 12.7795, 12.779, 12.7798, 12.781 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T10:54:03Z", "avg_ns": 346840420993, "stddev_ns": 3832873267, "avg_ts": 11.809533, "stddev_ts": 0.031472, "samples_ns": [ 346030273244, 346103135801, 346386989871, 347930791368, 347750914685 ],"samples_ts": [ 11.8371, 11.8346, 11.8249, 11.7725, 11.7785 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:22:59Z", "avg_ns": 72261509, "stddev_ns": 320576, "avg_ts": 13.838844, "stddev_ts": 0.061529, "samples_ns": [ 72477223, 72084030, 71789263, 72389907, 72567123 ],"samples_ts": [ 13.7974, 13.8727, 13.9297, 13.8141, 13.7803 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:02Z", "avg_ns": 84610779, "stddev_ns": 297122, "avg_ts": 23.637884, "stddev_ts": 0.083091, "samples_ns": [ 84734302, 84236302, 84357591, 84806048, 84919652 ],"samples_ts": [ 23.6032, 23.7427, 23.7086, 23.5832, 23.5517 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:05Z", "avg_ns": 101660351, "stddev_ns": 1547411, "avg_ts": 39.353916, "stddev_ts": 0.592095, "samples_ns": [ 101552409, 100600721, 101770982, 100204803, 104172840 ],"samples_ts": [ 39.3885, 39.7611, 39.3039, 39.9182, 38.3977 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:08Z", "avg_ns": 160767694, "stddev_ns": 4003119, "avg_ts": 49.785584, "stddev_ts": 1.222262, "samples_ns": [ 156557259, 158917148, 162293497, 159140740, 166929828 ],"samples_ts": [ 51.0995, 50.3407, 49.2934, 50.27, 47.9243 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:12Z", "avg_ns": 140731335, "stddev_ns": 1348186, "avg_ts": 113.700173, "stddev_ts": 1.091428, "samples_ns": [ 139439587, 139179515, 141106837, 141907469, 142023268 ],"samples_ts": [ 114.745, 114.959, 113.389, 112.75, 112.658 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:15Z", "avg_ns": 201649373, "stddev_ns": 2050614, "avg_ts": 158.704356, "stddev_ts": 1.605730, "samples_ns": [ 201358340, 199925462, 199744250, 202502762, 204716054 ],"samples_ts": [ 158.921, 160.06, 160.205, 158.023, 156.314 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:18Z", "avg_ns": 1036131963, "stddev_ns": 2376095, "avg_ts": 61.768454, "stddev_ts": 0.141639, "samples_ns": [ 1035551031, 1039403530, 1032900794, 1037093656, 1035710804 ],"samples_ts": [ 61.8028, 61.5738, 61.9614, 61.7109, 61.7933 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:27Z", "avg_ns": 1496730439, "stddev_ns": 10963991, "avg_ts": 85.523409, "stddev_ts": 0.625918, "samples_ns": [ 1492767974, 1512418344, 1482143011, 1497127885, 1499194981 ],"samples_ts": [ 85.7467, 84.6327, 86.3614, 85.497, 85.3792 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:38Z", "avg_ns": 2668611217, "stddev_ns": 2521222, "avg_ts": 95.930116, "stddev_ts": 0.090613, "samples_ns": [ 2665272144, 2671385608, 2668247232, 2667343518, 2670807586 ],"samples_ts": [ 96.0502, 95.8304, 95.9431, 95.9756, 95.8512 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:23:57Z", "avg_ns": 5379314882, "stddev_ns": 7430158, "avg_ts": 95.179552, "stddev_ts": 0.131395, "samples_ns": [ 5371323703, 5389789857, 5376238994, 5383947320, 5375274536 ],"samples_ts": [ 95.321, 94.9944, 95.2339, 95.0975, 95.2509 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:24:31Z", "avg_ns": 10617063118, "stddev_ns": 9112998, "avg_ts": 96.448575, "stddev_ts": 0.082758, "samples_ns": [ 10611605868, 10606636641, 10622080676, 10629893460, 10615098947 ],"samples_ts": [ 96.4981, 96.5433, 96.403, 96.3321, 96.4664 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T11:25:38Z", "avg_ns": 21250567167, "stddev_ns": 18931129, "avg_ts": 96.373960, "stddev_ts": 0.085846, "samples_ns": [ 21226255437, 21259461017, 21250300248, 21276301285, 21240517850 ],"samples_ts": [ 96.4843, 96.3336, 96.3751, 96.2573, 96.4195 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T11:28:47Z", "avg_ns": 72478508, "stddev_ns": 238023, "avg_ts": 13.797313, "stddev_ts": 0.045426, "samples_ns": [ 72560759, 72416537, 72706355, 72612627, 72096262 ],"samples_ts": [ 13.7816, 13.809, 13.754, 13.7717, 13.8703 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T11:28:49Z", "avg_ns": 144886396, "stddev_ns": 256034, "avg_ts": 13.803953, "stddev_ts": 0.024338, "samples_ns": [ 144838344, 144610193, 145247116, 145029355, 144706975 ],"samples_ts": [ 13.8085, 13.8303, 13.7696, 13.7903, 13.821 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T11:28:53Z", "avg_ns": 289827899, "stddev_ns": 393710, "avg_ts": 13.801314, "stddev_ts": 0.018718, "samples_ns": [ 289689562, 290189076, 289375689, 289597689, 290287482 ],"samples_ts": [ 13.8079, 13.7841, 13.8229, 13.8123, 13.7794 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T11:28:57Z", "avg_ns": 579882910, "stddev_ns": 462922, "avg_ts": 13.795896, "stddev_ts": 0.010984, "samples_ns": [ 580399062, 579336975, 580246043, 579491888, 579940586 ],"samples_ts": [ 13.7836, 13.8089, 13.7873, 13.8052, 13.7945 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T11:29:02Z", "avg_ns": 1159929949, "stddev_ns": 605719, "avg_ts": 13.793939, "stddev_ts": 0.007184, "samples_ns": [ 1158895210, 1160098755, 1160072655, 1160095058, 1160488071 ],"samples_ts": [ 13.8063, 13.7919, 13.7922, 13.792, 13.7873 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T11:29:10Z", "avg_ns": 2319053298, "stddev_ns": 2098159, "avg_ts": 13.798743, "stddev_ts": 0.012485, "samples_ns": [ 2321097995, 2321170313, 2319062862, 2317318868, 2316616452 ],"samples_ts": [ 13.7866, 13.7861, 13.7987, 13.8091, 13.8132 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T11:29:24Z", "avg_ns": 4628266701, "stddev_ns": 2900098, "avg_ts": 13.828075, "stddev_ts": 0.008659, "samples_ns": [ 4632982316, 4625738554, 4628184079, 4626034772, 4628393785 ],"samples_ts": [ 13.814, 13.8356, 13.8283, 13.8347, 13.8277 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T11:29:50Z", "avg_ns": 9269052247, "stddev_ns": 3464938, "avg_ts": 13.809396, "stddev_ts": 0.005160, "samples_ns": [ 9273506520, 9266619315, 9269695826, 9264698089, 9270741487 ],"samples_ts": [ 13.8028, 13.813, 13.8084, 13.8159, 13.8069 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T11:30:39Z", "avg_ns": 18508634753, "stddev_ns": 5304077, "avg_ts": 13.831383, "stddev_ts": 0.003962, "samples_ns": [ 18514997065, 18509767999, 18508646171, 18500274523, 18509488011 ],"samples_ts": [ 13.8266, 13.8305, 13.8314, 13.8376, 13.8307 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T11:32:14Z", "avg_ns": 37305088356, "stddev_ns": 4400074, "avg_ts": 13.724669, "stddev_ts": 0.001616, "samples_ns": [ 37310781397, 37302243186, 37300107557, 37303969026, 37308340618 ],"samples_ts": [ 13.7226, 13.7257, 13.7265, 13.7251, 13.7235 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T11:35:23Z", "avg_ns": 74908301101, "stddev_ns": 10022244, "avg_ts": 13.670047, "stddev_ts": 0.001828, "samples_ns": [ 74902917705, 74917375644, 74909384457, 74917688451, 74894139252 ],"samples_ts": [ 13.671, 13.6684, 13.6698, 13.6683, 13.6726 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T11:41:40Z", "avg_ns": 152551253066, "stddev_ns": 20211909, "avg_ts": 13.424996, "stddev_ts": 0.001779, "samples_ns": [ 152573333171, 152566129238, 152533162264, 152556306846, 152527333812 ],"samples_ts": [ 13.4231, 13.4237, 13.4266, 13.4246, 13.4271 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T11:54:25Z", "avg_ns": 314640925338, "stddev_ns": 31342605, "avg_ts": 13.018014, "stddev_ts": 0.001297, "samples_ns": [ 314587262401, 314663868734, 314656867427, 314639440752, 314657187380 ],"samples_ts": [ 13.0202, 13.0171, 13.0174, 13.0181, 13.0173 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:20:41Z", "avg_ns": 71608326, "stddev_ns": 233454, "avg_ts": 13.964975, "stddev_ts": 0.045428, "samples_ns": [ 71513061, 71810192, 71454219, 71899221, 71364941 ],"samples_ts": [ 13.9835, 13.9256, 13.995, 13.9084, 14.0125 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:20:43Z", "avg_ns": 83599959, "stddev_ns": 320877, "avg_ts": 23.923738, "stddev_ts": 0.091634, "samples_ns": [ 84069437, 83377109, 83234740, 83640656, 83677857 ],"samples_ts": [ 23.7899, 23.9874, 24.0284, 23.9118, 23.9012 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:20:46Z", "avg_ns": 100840589, "stddev_ns": 1623134, "avg_ts": 39.674790, "stddev_ts": 0.638698, "samples_ns": [ 101580005, 101219854, 99604772, 102937881, 98860437 ],"samples_ts": [ 39.3778, 39.5179, 40.1587, 38.8584, 40.4611 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:20:49Z", "avg_ns": 191319936, "stddev_ns": 1053945, "avg_ts": 41.815790, "stddev_ts": 0.230360, "samples_ns": [ 190242551, 192446986, 192270613, 191370642, 190268891 ],"samples_ts": [ 42.0516, 41.5699, 41.608, 41.8037, 42.0458 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:20:52Z", "avg_ns": 167514384, "stddev_ns": 2164396, "avg_ts": 95.526935, "stddev_ts": 1.233452, "samples_ns": [ 169460962, 164838198, 166685017, 166578707, 170009038 ],"samples_ts": [ 94.417, 97.0649, 95.9894, 96.0507, 94.1126 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:20:56Z", "avg_ns": 232816877, "stddev_ns": 2168695, "avg_ts": 137.456535, "stddev_ts": 1.268877, "samples_ns": [ 232830546, 236473870, 232247644, 230876373, 231655956 ],"samples_ts": [ 137.439, 135.322, 137.784, 138.602, 138.136 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:20:59Z", "avg_ns": 664923846, "stddev_ns": 766995, "avg_ts": 96.251726, "stddev_ts": 0.110912, "samples_ns": [ 664855529, 666128344, 664293948, 664239786, 665101624 ],"samples_ts": [ 96.2615, 96.0776, 96.3429, 96.3507, 96.2259 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:21:06Z", "avg_ns": 745867612, "stddev_ns": 3077155, "avg_ts": 171.614558, "stddev_ts": 0.707179, "samples_ns": [ 743000623, 746443208, 742813640, 746851079, 750229513 ],"samples_ts": [ 172.274, 171.48, 172.318, 171.386, 170.614 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:21:13Z", "avg_ns": 1126326444, "stddev_ns": 2652313, "avg_ts": 227.288579, "stddev_ts": 0.535796, "samples_ns": [ 1125364971, 1129024857, 1122365113, 1128378015, 1126499265 ],"samples_ts": [ 227.482, 226.744, 228.09, 226.874, 227.253 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:21:22Z", "avg_ns": 1505615369, "stddev_ns": 7330786, "avg_ts": 340.066741, "stddev_ts": 1.656150, "samples_ns": [ 1497324880, 1499001529, 1506731427, 1514266886, 1510752125 ],"samples_ts": [ 341.943, 341.561, 339.808, 338.117, 338.904 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:21:34Z", "avg_ns": 3141670610, "stddev_ns": 6323947, "avg_ts": 325.942294, "stddev_ts": 0.657070, "samples_ns": [ 3131377774, 3141568452, 3148551220, 3142931924, 3143923681 ],"samples_ts": [ 327.013, 325.952, 325.229, 325.81, 325.708 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:21:55Z", "avg_ns": 6663332748, "stddev_ns": 5209602, "avg_ts": 307.353854, "stddev_ts": 0.240488, "samples_ns": [ 6654377533, 6663916890, 6665884929, 6664731229, 6667753160 ],"samples_ts": [ 307.767, 307.327, 307.236, 307.289, 307.15 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T12:22:37Z", "avg_ns": 14462982255, "stddev_ns": 14034958, "avg_ts": 283.205981, "stddev_ts": 0.274705, "samples_ns": [ 14449735348, 14481872129, 14473863581, 14455279216, 14454161003 ],"samples_ts": [ 283.465, 282.836, 282.993, 283.357, 283.379 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T12:24:07Z", "avg_ns": 71509888, "stddev_ns": 141942, "avg_ts": 13.984124, "stddev_ts": 0.027772, "samples_ns": [ 71392997, 71330318, 71615318, 71656976, 71553831 ],"samples_ts": [ 14.007, 14.0193, 13.9635, 13.9554, 13.9755 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T12:24:10Z", "avg_ns": 143329643, "stddev_ns": 720541, "avg_ts": 13.954128, "stddev_ts": 0.069718, "samples_ns": [ 142965784, 144591897, 142803798, 143191129, 143095609 ],"samples_ts": [ 13.9894, 13.832, 14.0052, 13.9673, 13.9767 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T12:24:13Z", "avg_ns": 286362372, "stddev_ns": 613128, "avg_ts": 13.968367, "stddev_ts": 0.029875, "samples_ns": [ 286186169, 286447453, 286269376, 287302739, 285606124 ],"samples_ts": [ 13.9769, 13.9642, 13.9729, 13.9226, 14.0053 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T12:24:17Z", "avg_ns": 573176885, "stddev_ns": 926849, "avg_ts": 13.957326, "stddev_ts": 0.022587, "samples_ns": [ 573966892, 572709305, 573925494, 573495281, 571787454 ],"samples_ts": [ 13.9381, 13.9687, 13.9391, 13.9495, 13.9912 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T12:24:22Z", "avg_ns": 1146719495, "stddev_ns": 778559, "avg_ts": 13.952851, "stddev_ts": 0.009473, "samples_ns": [ 1145876287, 1146009469, 1146896987, 1147747694, 1147067038 ],"samples_ts": [ 13.9631, 13.9615, 13.9507, 13.9403, 13.9486 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T12:24:31Z", "avg_ns": 2288962403, "stddev_ns": 1593341, "avg_ts": 13.980139, "stddev_ts": 0.009727, "samples_ns": [ 2289870722, 2290984247, 2287185620, 2289225596, 2287545832 ],"samples_ts": [ 13.9746, 13.9678, 13.991, 13.9785, 13.9888 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T12:24:45Z", "avg_ns": 4584827592, "stddev_ns": 2244358, "avg_ts": 13.959088, "stddev_ts": 0.006826, "samples_ns": [ 4588406982, 4582664784, 4585045336, 4583220371, 4584800490 ],"samples_ts": [ 13.9482, 13.9657, 13.9584, 13.964, 13.9592 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T12:25:10Z", "avg_ns": 9208291679, "stddev_ns": 1044930, "avg_ts": 13.900516, "stddev_ts": 0.001571, "samples_ns": [ 9209533074, 9208233802, 9209098841, 9207019425, 9207573255 ],"samples_ts": [ 13.8986, 13.9006, 13.8993, 13.9024, 13.9016 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T12:25:58Z", "avg_ns": 18524398839, "stddev_ns": 6515779, "avg_ts": 13.819613, "stddev_ts": 0.004860, "samples_ns": [ 18534183776, 18526747473, 18521506639, 18522735699, 18516820608 ],"samples_ts": [ 13.8123, 13.8179, 13.8218, 13.8209, 13.8253 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T12:27:33Z", "avg_ns": 37515578354, "stddev_ns": 6050053, "avg_ts": 13.647664, "stddev_ts": 0.002201, "samples_ns": [ 37515192603, 37524987007, 37509253521, 37511574351, 37516884288 ],"samples_ts": [ 13.6478, 13.6442, 13.65, 13.6491, 13.6472 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T12:30:43Z", "avg_ns": 76546199400, "stddev_ns": 10120024, "avg_ts": 13.377542, "stddev_ts": 0.001769, "samples_ns": [ 76540245784, 76536847767, 76539669712, 76555422470, 76558811267 ],"samples_ts": [ 13.3786, 13.3792, 13.3787, 13.3759, 13.3753 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T12:37:09Z", "avg_ns": 160386886028, "stddev_ns": 14068063, "avg_ts": 12.769124, "stddev_ts": 0.001119, "samples_ns": [ 160385984850, 160395287205, 160370659480, 160376794024, 160405704584 ],"samples_ts": [ 12.7692, 12.7685, 12.7704, 12.7699, 12.7676 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": false, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T12:50:33Z", "avg_ns": 346468001815, "stddev_ns": 28226134, "avg_ts": 11.822160, "stddev_ts": 0.000963, "samples_ns": [ 346495621317, 346472089330, 346471189940, 346480456706, 346420651782 ],"samples_ts": [ 11.8212, 11.822, 11.8221, 11.8217, 11.8238 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:28Z", "avg_ns": 72527545, "stddev_ns": 285957, "avg_ts": 13.788036, "stddev_ts": 0.054282, "samples_ns": [ 72262075, 72266263, 72939185, 72506768, 72663434 ],"samples_ts": [ 13.8385, 13.8377, 13.7101, 13.7918, 13.7621 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:31Z", "avg_ns": 84341257, "stddev_ns": 295262, "avg_ts": 23.713419, "stddev_ts": 0.082918, "samples_ns": [ 84668631, 84312317, 84093834, 84613676, 84017831 ],"samples_ts": [ 23.6215, 23.7213, 23.783, 23.6368, 23.8045 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:33Z", "avg_ns": 100448089, "stddev_ns": 1376154, "avg_ts": 39.827511, "stddev_ts": 0.542639, "samples_ns": [ 99626157, 102516779, 100454030, 98863855, 100779626 ],"samples_ts": [ 40.1501, 39.018, 39.8192, 40.4597, 39.6906 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 8, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:36Z", "avg_ns": 162352363, "stddev_ns": 2648579, "avg_ts": 49.285856, "stddev_ts": 0.790669, "samples_ns": [ 166890598, 161770231, 161622202, 159906329, 161572458 ],"samples_ts": [ 47.9356, 49.4529, 49.4982, 50.0293, 49.5134 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 16, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:40Z", "avg_ns": 138993062, "stddev_ns": 1344785, "avg_ts": 115.122215, "stddev_ts": 1.105494, "samples_ns": [ 137716356, 138099781, 139139856, 138834930, 141174391 ],"samples_ts": [ 116.181, 115.858, 114.992, 115.245, 113.335 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 32, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:43Z", "avg_ns": 201669979, "stddev_ns": 1884124, "avg_ts": 158.686158, "stddev_ts": 1.482180, "samples_ns": [ 203400190, 199467730, 200269384, 203755452, 201457139 ],"samples_ts": [ 157.325, 160.427, 159.785, 157.051, 158.843 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 64, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:46Z", "avg_ns": 635967841, "stddev_ns": 1475057, "avg_ts": 100.634452, "stddev_ts": 0.233381, "samples_ns": [ 637688056, 634116156, 637195065, 635098763, 635741167 ],"samples_ts": [ 100.363, 100.928, 100.44, 100.772, 100.67 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 128, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:53Z", "avg_ns": 716152722, "stddev_ns": 1325234, "avg_ts": 178.733315, "stddev_ts": 0.330530, "samples_ns": [ 717462979, 714859369, 715921736, 714926826, 717592704 ],"samples_ts": [ 178.406, 179.056, 178.79, 179.039, 178.374 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 256, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:19:59Z", "avg_ns": 1090985202, "stddev_ns": 2924974, "avg_ts": 234.651643, "stddev_ts": 0.628423, "samples_ns": [ 1088017626, 1091174412, 1091904131, 1088538220, 1095291622 ],"samples_ts": [ 235.29, 234.61, 234.453, 235.178, 233.728 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 512, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:20:08Z", "avg_ns": 1389283652, "stddev_ns": 4439595, "avg_ts": 368.538271, "stddev_ts": 1.181362, "samples_ns": [ 1392829628, 1389957550, 1392381611, 1381788844, 1389460631 ],"samples_ts": [ 367.597, 368.357, 367.715, 370.534, 368.488 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 1024, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:20:19Z", "avg_ns": 2810952737, "stddev_ns": 6147665, "avg_ts": 364.290691, "stddev_ts": 0.796196, "samples_ns": [ 2819392221, 2814916634, 2809039788, 2807373930, 2804041112 ],"samples_ts": [ 363.199, 363.776, 364.537, 364.754, 365.187 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 2048, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:20:38Z", "avg_ns": 5665746580, "stddev_ns": 8516928, "avg_ts": 361.471110, "stddev_ts": 0.543593, "samples_ns": [ 5653719396, 5674494425, 5664429325, 5673368167, 5662721587 ],"samples_ts": [ 362.239, 360.913, 361.555, 360.985, 361.664 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 4096, "n_gen": 0, "n_depth": 0, "test_time": "2025-08-07T13:21:15Z", "avg_ns": 11777945646, "stddev_ns": 20037399, "avg_ts": 347.769433, "stddev_ts": 0.591042, "samples_ns": [ 11761558675, 11777075068, 11759198703, 11808928548, 11782967240 ],"samples_ts": [ 348.253, 347.794, 348.323, 346.856, 347.62 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1, "n_depth": 0, "test_time": "2025-08-07T13:22:28Z", "avg_ns": 72380578, "stddev_ns": 203747, "avg_ts": 13.815948, "stddev_ts": 0.038882, "samples_ns": [ 72420500, 72462098, 72232464, 72654221, 72133607 ],"samples_ts": [ 13.8082, 13.8003, 13.8442, 13.7638, 13.8632 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2, "n_depth": 0, "test_time": "2025-08-07T13:22:31Z", "avg_ns": 144869779, "stddev_ns": 436916, "avg_ts": 13.805602, "stddev_ts": 0.041613, "samples_ns": [ 145465679, 144355532, 144960013, 144538037, 145029635 ],"samples_ts": [ 13.7489, 13.8547, 13.7969, 13.8372, 13.7903 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4, "n_depth": 0, "test_time": "2025-08-07T13:22:34Z", "avg_ns": 289759556, "stddev_ns": 621884, "avg_ts": 13.804600, "stddev_ts": 0.029577, "samples_ns": [ 289432325, 289990721, 289357434, 290750487, 289266813 ],"samples_ts": [ 13.8202, 13.7935, 13.8237, 13.7575, 13.8281 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 8, "n_depth": 0, "test_time": "2025-08-07T13:22:38Z", "avg_ns": 578838645, "stddev_ns": 640028, "avg_ts": 13.820791, "stddev_ts": 0.015255, "samples_ns": [ 578596273, 579009394, 578037679, 579786684, 578763199 ],"samples_ts": [ 13.8266, 13.8167, 13.8399, 13.7982, 13.8226 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 16, "n_depth": 0, "test_time": "2025-08-07T13:22:43Z", "avg_ns": 1161423151, "stddev_ns": 901088, "avg_ts": 13.776209, "stddev_ts": 0.010684, "samples_ns": [ 1161250465, 1160522469, 1160743857, 1162751942, 1161847022 ],"samples_ts": [ 13.7783, 13.7869, 13.7843, 13.7605, 13.7712 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 32, "n_depth": 0, "test_time": "2025-08-07T13:22:51Z", "avg_ns": 2313692305, "stddev_ns": 1789504, "avg_ts": 13.830713, "stddev_ts": 0.010700, "samples_ns": [ 2314179302, 2315898621, 2311005494, 2313196443, 2314181665 ],"samples_ts": [ 13.8278, 13.8175, 13.8468, 13.8337, 13.8278 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 64, "n_depth": 0, "test_time": "2025-08-07T13:23:05Z", "avg_ns": 4636372495, "stddev_ns": 1661076, "avg_ts": 13.803897, "stddev_ts": 0.004944, "samples_ns": [ 4639138340, 4635414931, 4636346420, 4636145117, 4634817667 ],"samples_ts": [ 13.7957, 13.8067, 13.804, 13.8046, 13.8085 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 128, "n_depth": 0, "test_time": "2025-08-07T13:23:31Z", "avg_ns": 9253071159, "stddev_ns": 2341634, "avg_ts": 13.833246, "stddev_ts": 0.003497, "samples_ns": [ 9253822232, 9252269981, 9254796147, 9255087952, 9249379486 ],"samples_ts": [ 13.8321, 13.8344, 13.8307, 13.8302, 13.8388 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 256, "n_depth": 0, "test_time": "2025-08-07T13:24:20Z", "avg_ns": 18547219708, "stddev_ns": 4845754, "avg_ts": 13.802609, "stddev_ts": 0.003606, "samples_ns": [ 18552795644, 18549257160, 18546292732, 18539667426, 18548085579 ],"samples_ts": [ 13.7985, 13.8011, 13.8033, 13.8082, 13.802 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 512, "n_depth": 0, "test_time": "2025-08-07T13:25:55Z", "avg_ns": 37297500329, "stddev_ns": 5986743, "avg_ts": 13.727462, "stddev_ts": 0.002201, "samples_ns": [ 37301095380, 37296290320, 37288859825, 37296477534, 37304778590 ],"samples_ts": [ 13.7261, 13.7279, 13.7306, 13.7278, 13.7248 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 1024, "n_depth": 0, "test_time": "2025-08-07T13:29:04Z", "avg_ns": 74917431551, "stddev_ns": 6087685, "avg_ts": 13.668381, "stddev_ts": 0.001109, "samples_ns": [ 74916037289, 74925918600, 74918791141, 74917462498, 74908948230 ],"samples_ts": [ 13.6686, 13.6668, 13.6681, 13.6684, 13.6699 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 2048, "n_depth": 0, "test_time": "2025-08-07T13:35:21Z", "avg_ns": 152497993558, "stddev_ns": 8211748, "avg_ts": 13.429685, "stddev_ts": 0.000722, "samples_ns": [ 152499908396, 152509109899, 152496323232, 152486232543, 152498393724 ],"samples_ts": [ 13.4295, 13.4287, 13.4298, 13.4307, 13.4296 ]}
{"build_commit": "83bc2f28", "build_number": 6077, "cpu_info": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S", "gpu_info": "AMD Radeon Graphics", "backends": "ROCm", "model_filename": "/models/gguf/Mistral-Small-3.1-24B-Instruct-2503-UD-Q4_K_XL.gguf", "model_type": "llama 13B Q4_K - Medium", "model_size": 14497730560, "model_n_params": 23572403200, "n_batch": 2048, "n_ubatch": 512, "n_threads": 16, "cpu_mask": "0x0", "cpu_strict": false, "poll": 50, "type_k": "f16", "type_v": "f16", "n_gpu_layers": 99, "split_mode": "layer", "main_gpu": 0, "no_kv_offload": false, "flash_attn": true, "tensor_split": "0.00", "tensor_buft_overrides": "none", "defrag_thold": -1.000000, "use_mmap": false, "embeddings": false, "no_op_offload": 0, "n_prompt": 0, "n_gen": 4096, "n_depth": 0, "test_time": "2025-08-07T13:48:06Z", "avg_ns": 314398153129, "stddev_ns": 11488155, "avg_ts": 13.028066, "stddev_ts": 0.000476, "samples_ns": [ 314386623291, 314395133584, 314406908782, 314413141539, 314388958449 ],"samples_ts": [ 13.0285, 13.0282, 13.0277, 13.0274, 13.0284 ]}
